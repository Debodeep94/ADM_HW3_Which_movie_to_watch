{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [1.1] Get the list of movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start downloading the html files with inside the urls of the documents we need!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://en.wikipedia.org/wiki/10_to_Midnight'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup = BeautifulSoup(open('C:/Users/leona/Desktop/ADMHMK-3/movies2.html'), \"html.parser\")\n",
    "soup.head()\n",
    "lst_a = soup.select('a')\n",
    "urls = []\n",
    "for i in lst_a:\n",
    "    urls.append(i.get('href'))\n",
    "urls[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://en.wikipedia.org/wiki/Love_by_the_Light_of_the_Moon'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup = BeautifulSoup(open('C:/Users/leona/Desktop/ADMHMK-3/movies1.html'), \"html.parser\")\n",
    "soup.head()\n",
    "lst_a = soup.select('a')\n",
    "lst_a\n",
    "for i in lst_a:\n",
    "    urls.append(i.get('href'))\n",
    "urls[10000]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://en.wikipedia.org/wiki/Z.P.G.'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup = BeautifulSoup(open('C:/Users/leona/Desktop/ADMHMK-3/movies3.html'), \"html.parser\")\n",
    "soup.head()\n",
    "lst_a = soup.select('a')\n",
    "lst_a\n",
    "for i in lst_a:\n",
    "    urls.append(i.get('href'))\n",
    "urls[20000] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://en.wikipedia.org/wiki/Whistle_(2003_film)'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls[29999]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have all 30.000 urls we need to save them in dictionary that we will access later when we want to print the urls in the output of the search engines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicturls = {}\n",
    "for i in range(len(urls)):\n",
    "    dicturls[i] = urls[i]\n",
    "with open('dicturls.json', 'w') as fp:\n",
    "    json.dump(dicturls, fp)\n",
    "with open(r\"C:\\Users\\leona\\Desktop\\ADMHMK-3\\dicturls.json\", 'r') as file:\n",
    "    data = file.read()\n",
    "dicturls = json.loads(data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://en.wikipedia.org/wiki/Whistle_(2003_film)'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dicturls[str(29999)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [1.2] Crawl Wikipedia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, avoiding any error,(there will not be, and knowing this I already saved in order the urls), we download on our pc the html files we need for our database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.error import URLError, HTTPError, ContentTooShortError\n",
    "import time\n",
    "def getwikipageshtml(urls):\n",
    "    k=0\n",
    "    for i in range(len(urls)):\n",
    "        try:\n",
    "            ur_l = requests.get(urls[i])\n",
    "            soup = BeautifulSoup(ur_l.content, 'html.parser')\n",
    "            soup = soup.prettify(\"utf-8\")   \n",
    "            stringa = 'Articles/article-'+str(k)+'.html'\n",
    "            k = k+1\n",
    "            Html_file= open(stringa, \"wb\")\n",
    "            Html_file.write(soup)\n",
    "            Html_file.close()\n",
    "        except(URLError,HTTPError, ContentTooShortError)  as e:\n",
    "            html = None\n",
    "        #time.sleep(0.001) #Actually for this task we don't need to stop anytime\n",
    "    return\n",
    "getwikipageshtml(urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [1.3] Parse downloaded pages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we access every html document and take out the informations we need to build our tsv files with info title, intro, plot, film_name, director, producer, writer, starring, music, release date, runtime, country, language, budget."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import io\n",
    "for i in range(30000):\n",
    "    filename = \"Articles/article-\"+str(i)+\".html\"\n",
    "    with open(filename, encoding=\"utf-8\") as f:\n",
    "        data = f.read()\n",
    "        soup = BeautifulSoup(data, 'html.parser')\n",
    "        #Now That I opened the file I have to look for the section asked\n",
    "        #first I take the title and clear him of spaces and the word -Wikipedia\n",
    "        titlepage = soup.title.string\n",
    "        titleonly = titlepage.split(\"- Wikipedia\")\n",
    "        titlepage = titleonly[0].strip()\n",
    "        #now I create empty string as intro and plot\n",
    "        intro = ''\n",
    "        plot = ''\n",
    "        #Now i searcvh the first paragraph that usually or is empty or is the intro\n",
    "        start = soup.find('p')\n",
    "        intro = start\n",
    "        intro1 = start.text\n",
    "        B = ''\n",
    "        #in B I put m,y limit for the paragraphs in the intro, because after this h2 there will always be the plot\n",
    "        B = intro.find_next_sibling('h2')\n",
    "        if(B!=None and B.find_next_sibling('p')):\n",
    "            C = B.find_next_sibling('p')\n",
    "            while(C != intro.find_next_sibling('p')): \n",
    "                intro1 = intro1 + intro.find_next_sibling('p').text\n",
    "                intro = intro.find_next_sibling('p')\n",
    "            plot = ''    \n",
    "            #then i do the same with the plot, so I start at B and end in the next h2\n",
    "            plot = B\n",
    "            plot1 = ''\n",
    "            compare = ''\n",
    "            if(B.find_next_sibling('h2')):\n",
    "                compare = B.find_next_sibling('h2')\n",
    "                compareto = compare.find_next_sibling('p')\n",
    "                while(compareto != plot.find_next_sibling('p')):\n",
    "                    plot1 = plot1 + plot.find_next_sibling('p').text\n",
    "                    #print(plot1)\n",
    "                    plot = plot.find_next_sibling('p')\n",
    "                    #if plot or intro are empty I put NA\n",
    "        if(intro1 == ''):\n",
    "            intro1 = \"NA\"\n",
    "        if plot1 == '':\n",
    "            plot1 = \"NA\"\n",
    "        #Now I start working on the other features\n",
    "        intro = intro1\n",
    "        plot = plot1\n",
    "        film_name = 'NA'\n",
    "        director = \"NA\"\n",
    "        producer = \"NA\"\n",
    "        writer = \"NA\"\n",
    "        starring = \"NA\"\n",
    "        music = \"NA\"\n",
    "        release_date = \"NA\"\n",
    "        runtime = \"NA\"\n",
    "        country = \"NA\"\n",
    "        language = \"NA\"\n",
    "        budget = \"NA\"\n",
    "#'film_name', 'director', 'producer','writer', 'starring', 'music', 'release date', 'runtime', 'country', 'language', 'budget'\n",
    "        for link in soup.find_all('tr'):\n",
    "            if soup.find('th',{'class': ['summary']})!= None:\n",
    "                    film_name = soup.find('th',{'class': ['summary']} ).text.strip()\n",
    "            if link.th:\n",
    "#I just check in the th and if I find the class I need I take the relative td. Some of them are inaccessible so the if link.td\n",
    "                if(link.th.text.strip() == 'Directed by'):\n",
    "                     director = link.td.text.strip()\n",
    "                elif(link.th.text.strip() == 'Produced by'):\n",
    "                      producer = link.td.text.strip()\n",
    "                elif(link.th.text.strip() == 'Written by'):\n",
    "                    writer = link.td.text.strip()\n",
    "                elif(link.th.text.strip() == 'Starring'):\n",
    "                    starring = link.td.text.strip()\n",
    "                elif(link.th.text.strip() == 'Music by'):\n",
    "                     music = link.td.text.strip()               \n",
    "                elif(link.th.text.strip() == 'Release date'):\n",
    "                    if link.td:\n",
    "                        release_date = link.td.text.strip()\n",
    "                elif(link.th.text.strip() == 'Running time'):\n",
    "                    runtime = link.td.text.strip()\n",
    "                elif(link.th.text.strip() == 'Country'):\n",
    "                    if link.td:\n",
    "                        country = link.td.text.strip()\n",
    "                elif(link.th.text.strip() == 'Language'):\n",
    "                    if link.td:\n",
    "                        language = link.td.text.strip()\n",
    "                elif(link.th.text.strip() == 'Budget'):\n",
    "                    budget = link.td.text.strip()\n",
    "#now I open the tsv files and create one for every film.        \n",
    "        tsvname = 'Tsvfiles/'+'film'+str(i)+'.tsv'\n",
    "        with io.open(tsvname, \"w\", encoding=\"utf-8\") as out_file:\n",
    "            tsv_writer = csv.writer(out_file, delimiter='\\t')\n",
    "            tsv_writer.writerow(['title','intro', 'plot', 'film_name', 'director', 'producer','writer', 'starring', 'music', 'release date', 'runtime', 'country', 'language', 'budget'])\n",
    "            tsv_writer.writerow([titlepage, intro, plot, film_name, director, producer, writer, starring, music, release_date, runtime, \n",
    "                 country, language, budget])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Whistle (2003 film)'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titlepage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n\\n\\n         What Became of Jack and Jill?\\n        \\n\\n       is a 1972 British\\n       \\n        horror film\\n       \\n       directed by\\n       \\n        Bill Bain\\n       \\n       and starring\\n       \\n        Mona Washbourne\\n       \\n       ,\\n       \\n        Paul Nicholas\\n       \\n       , and\\n       \\n        Vanessa Howard\\n       \\n       .\\n       \\n\\n         [1]\\n        \\n\\n       It was part of an abandoned attempt by\\n       \\n        Amicus Pictures\\n       \\n       to compete with\\n       \\n        Hammer Studios\\n       \\n       by breaking into the\\n       \\n        grindhouse\\n       \\n       market. Studio executives were ultimately too disturbed by the final product to release it under the Amicus name, and they sold the film to\\n       \\n        20th Century Fox\\n       \\n       .\\n      '"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this is just to try stuff."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we clean The files, so we first define a preprocess function to do it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io \n",
    "import nltk\n",
    "import csv\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    "stop_words = set(stopwords.words('english')) \n",
    "from nltk.stem import PorterStemmer \n",
    "\n",
    " \n",
    "ps = PorterStemmer() \n",
    "#the fuction preprocess the string as asked in the hmk\n",
    "def preprocess(sentence):\n",
    "    sentence = sentence.lower()\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokens = tokenizer.tokenize(sentence)\n",
    "    filtered_words = [ps.stem(w) for w in tokens if not w in stopwords.words('english')]\n",
    "    return \" \".join(filtered_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the function on every section of the tsv files, except for the tiles of the categories, so from the part 13 and clean them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 midnight\n",
      "10 midnight 1983 american crime horror thriller film 3 direct j lee thompson screenplay origin written william robert film star charl bronson lead role support cast includ lisa eilbach andrew steven gene davi geoffrey lewi wilford brimley 10 midnight releas citi film subsidiari cannon film american cinema march 11 1983\n",
      "warren staci gene davi young offic equip repairman kill women reject sexual advanc attempt flirt alway seen creepi women result frequent reject 4 first victim betti june gilbert offic worker acquaint track wood area observ sex boyfriend ambush coupl kill boyfriend give chase nake woman catch stab death 4 two lo angel polic detect leo kessler charl bronson paul mcann andrew steven investig murder kessler season veteran forc mcann consider younger 4 staci avoid prosecut construct sound alibi assault victim nake except pair latex glove hide fingerprint thu minim evid lauri kessler lisa eilbach daughter leo acquaint victim student nurs becom target killer 4 mcann refus go along kessler plant evid order frame suspect staci goe anoth rampag kill three nurs student friend kessler daughter eventu caught stark nake street staci boast say thing prove crazi hear voic order thing etc one day back street kessler well whole fuck world hear kessler repli shoot staci forehead execut leav consider asid kessler stand bodi surround polic\n",
      "10 midnight\n",
      "j lee thompson\n",
      "pancho kohner lanc hool\n",
      "william robert j lee thompson\n",
      "charl bronson lisa eilbach andrew steven gene davi geoffrey lewi wilford brimley\n",
      "robert ragland\n",
      "march 11 1983 1983 03 11 u\n",
      "101 min\n",
      "unit state\n",
      "english\n",
      "4 520 000 us\n"
     ]
    }
   ],
   "source": [
    "for i in range(30000):\n",
    "    file1 = open('Tsvfiles/film'+str(i)+'.tsv', encoding=\"utf8\") \n",
    "    line = file1.read()# Use this to read file content as a stream: \n",
    "    words = line.split('\\t') \n",
    "    for j in range(13, len(words)):\n",
    "        words[j] = preprocess(words[j])\n",
    "        if j ==13:\n",
    "            #Here for the format of tsv files and my split('\\t') the word budget would always be in my title, so I take her out\n",
    "            words[j] = words[j].replace('budget ','')  \n",
    "            words[j] = words[j].replace('budget\\n\\n','')\n",
    "        print(words[j])\n",
    "    tsvname = \"Cleantsv/filmclean-\"+str(i)+'.tsv'\n",
    "    with io.open(tsvname, \"w\", encoding=\"utf-8\") as out_file:\n",
    "            tsv_writer = csv.writer(out_file, delimiter='\\t')\n",
    "            tsv_writer.writerow(['title','intro', 'plot', 'film_name', 'director', 'producer','writer', 'starring', 'music', 'release date', 'runtime', 'country', 'language', 'budget'])\n",
    "            tsv_writer.writerow(words[13:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'10 midnight'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[13]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EX[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1.1) Create your index!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now from the clean intro and plots we start building the dictionary that will have \"index\":word, so we have a unique associatioin between a word in the dataset we care about and a number. Obviously we will save it as json file, as many other dictionaries that follow to be able to use them when we want in our search engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionar = {}\n",
    "k = 0\n",
    "for i in range(30000):\n",
    "    file1 = open(\"Cleantsv/filmclean-\"+str(i)+'.tsv', encoding=\"utf8\") \n",
    "    line = file1.read()# Use this to read file content as a stream: \n",
    "    #print(line)\n",
    "    words = line.split('\\t') \n",
    "    wordssplitted1 = words[14].split()\n",
    "    wordssplitted2 = words[15].split()\n",
    "    #print(wordssplitted1, wordssplitted2)\n",
    "    for i in wordssplitted1:\n",
    "        #print(type(i))\n",
    "        if i not in dictionar:\n",
    "            dictionar[i] = str(k)\n",
    "            k = k+1\n",
    "    for i in wordssplitted2:\n",
    "        #print(type(i))\n",
    "        if i not in dictionar:\n",
    "            dictionar[i] = str(k)\n",
    "            k = k+1\n",
    "#dictionar\n",
    "import json\n",
    "\n",
    "with open('Dictionary.json', 'w') as fp:\n",
    "    json.dump(dictionar, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'12741'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "with open(r\"C:\\Users\\leona\\Desktop\\ADMHMK-3\\Dictionary.json\", 'r') as file:\n",
    "    data = file.read()\n",
    "diction = json.loads(data)\n",
    "diction['1913']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(diction)\n",
    "type(diction['hom'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here is the inverted Dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we build the inverted dictionary that for each index has as value the nanme of the documents we know have the word that in the previous dictionary has that unique index. We save it as json file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dictionar2 = {}\n",
    "length = 0\n",
    "for i in range(30000):\n",
    "    file = \"Cleantsv/filmclean-\"+str(i)+'.tsv'\n",
    "    file1 = open(file, encoding=\"utf8\") \n",
    "    line = file1.read()# Use this to read file content as a stream: \n",
    "    #print(line)\n",
    "    words = line.split('\\t') \n",
    "    wordssplitted1 = words[14].split()\n",
    "    wordssplitted2 = words[15].split()\n",
    "    #print(wordssplitted1, wordssplitted2)\n",
    "    for j in wordssplitted1:\n",
    "        code = diction[j]\n",
    "        if code not in dictionar2:\n",
    "            dictionar2[code] = [file]\n",
    "        elif file not in dictionar2[code]:\n",
    "            dictionar2[code].append(file)\n",
    "    for j in wordssplitted2:\n",
    "        code = diction[j]\n",
    "        if code not in dictionar2:\n",
    "            dictionar2[code] = [file]\n",
    "        elif file not in dictionar2[code]:\n",
    "            dictionar2[code].append(file)\n",
    "#dictionar\n",
    "import json\n",
    "\n",
    "with open('Dictionary1.json', 'w') as fp:\n",
    "    json.dump(dictionar2, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "with open(r\"C:\\Users\\leona\\Desktop\\ADMHMK-3\\Dictionary1.json\", 'r') as file:\n",
    "    data = file.read()\n",
    "diction2 = json.loads(data)\n",
    "#dictions = pd.DataFrame(diction)\n",
    "#diction2['0']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114796"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diction['2019']\n",
    "len(diction2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1.2) Execute the query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First engine searchengine1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we remind some funcion we need to use and the vocabularies, so the following cell must not be run, but just used to remind the instruments we are using and defining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(r\"C:\\Users\\leona\\Desktop\\ADMHMK-3\\dicturls.json\", 'r') as file:\n",
    "    data = file.read()\n",
    "dicturls = json.loads(data) \n",
    "import pandas as pd\n",
    "with open(r\"C:\\Users\\leona\\Desktop\\ADMHMK-3\\Dictionary.json\", 'r') as file:\n",
    "    data = file.read()\n",
    "diction = json.loads(data)\n",
    "with open(r\"C:\\Users\\leona\\Desktop\\ADMHMK-3\\Dictionary1.json\", 'r') as file:\n",
    "    data = file.read()\n",
    "diction2 = json.loads(data)\n",
    "import io \n",
    "import nltk\n",
    "import csv\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    "stop_words = set(stopwords.words('english')) \n",
    "from nltk.stem import PorterStemmer \n",
    "\n",
    "\n",
    " \n",
    "ps = PorterStemmer() \n",
    "#the fuction preprocess the string as asked in the hmk\n",
    "def preprocess(sentence):\n",
    "    sentence = sentence.lower()\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokens = tokenizer.tokenize(sentence)\n",
    "    filtered_words = [ps.stem(w) for w in tokens if not w in stopwords.words('english')]\n",
    "    return \" \".join(filtered_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the code for the engine as a function that takes a input to analyze. It will give all the documents that will match all the words of the input inside their intro or plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gothic film novel\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Intro</th>\n",
       "      <th>Url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cross Creek (film)</td>\n",
       "      <td>Cross Creek               is a 1983 f...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Cross_Creek_(film)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Interview with the Vampire (film)</td>\n",
       "      <td>Interview with the Vampire           ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Interview_with_t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Hunchback of Notre Dame (1996 film)</td>\n",
       "      <td>The Hunchback of Notre Dame          ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Hunchback_of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Big Fish</td>\n",
       "      <td>Big Fish               is a 2003 Amer...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Big_Fish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lemony Snicket's A Series of Unfortunate Events</td>\n",
       "      <td>Lemony Snicket's A Series of Unfortun...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Lemony_Snicket%2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The Crow: Wicked Prayer</td>\n",
       "      <td>The Crow: Wicked Prayer              ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Crow:_Wicked...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Miracle at St. Anna</td>\n",
       "      <td>Miracle at St. Anna               is ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Miracle_at_St._Anna</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Beautiful Creatures (2013 film)</td>\n",
       "      <td>Beautiful Creatures               is ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Beautiful_Creatu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The Scribbler (film)</td>\n",
       "      <td>The Scribbler               is a 2014...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Scribbler_(f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Crimson Peak</td>\n",
       "      <td>Crimson Peak               is a 2015 ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Crimson_Peak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>The Beguiled (2017 film)</td>\n",
       "      <td>The Beguiled               is a 2017 ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Beguiled_(20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>On the Night of the Fire</td>\n",
       "      <td>On the Night of the Fire             ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/On_the_Night_of_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>The Three Weird Sisters</td>\n",
       "      <td>The Three Weird Sisters              ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Three_Weird_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>The Curse of Frankenstein</td>\n",
       "      <td>The Curse of Frankenstein            ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Curse_of_Fra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>The Hound of the Baskervilles (1959 film)</td>\n",
       "      <td>The Hound of the Baskervilles        ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Hound_of_the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Frankenstein (1931 film)</td>\n",
       "      <td>Frankenstein               is a 1931 ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Frankenstein_(19...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>The House of the Seven Gables (film)</td>\n",
       "      <td>The House of the Seven Gables        ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_House_of_the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Rebecca (1940 film)</td>\n",
       "      <td>Rebecca               is a 1940 Ameri...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Rebecca_(1940_film)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Dark Waters (1944 film)</td>\n",
       "      <td>Dark Waters               is a 1944  ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Dark_Waters_(194...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>My Name Is Julia Ross</td>\n",
       "      <td>My Name Is Julia Ross               i...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/My_Name_Is_Julia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>So Evil My Love</td>\n",
       "      <td>So Evil My Love               is a 19...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/So_Evil_My_Love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Moonfleet (1955 film)</td>\n",
       "      <td>Moonfleet               is a 1955    ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Moonfleet_(1955_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Psycho (1960 film)</td>\n",
       "      <td>Psycho               is a 1960 Americ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Psycho_(1960_film)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>The Beguiled (1971 film)</td>\n",
       "      <td>The Beguiled               is a 1971 ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Beguiled_(19...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>A Handful of Dust (film)</td>\n",
       "      <td>A Handful of Dust               is a ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/A_Handful_of_Dus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Jane Eyre (2011 film)</td>\n",
       "      <td>Jane Eyre               is a 2011 Bri...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Jane_Eyre_(2011_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>The Woman in Black (2012 film)</td>\n",
       "      <td>The Woman in Black               is a...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Woman_in_Bla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Dracula</td>\n",
       "      <td>Dracula               is an 1897     ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Dracula</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Title  \\\n",
       "0                                Cross Creek (film)   \n",
       "1                 Interview with the Vampire (film)   \n",
       "2           The Hunchback of Notre Dame (1996 film)   \n",
       "3                                          Big Fish   \n",
       "4   Lemony Snicket's A Series of Unfortunate Events   \n",
       "5                           The Crow: Wicked Prayer   \n",
       "6                               Miracle at St. Anna   \n",
       "7                   Beautiful Creatures (2013 film)   \n",
       "8                              The Scribbler (film)   \n",
       "9                                      Crimson Peak   \n",
       "10                         The Beguiled (2017 film)   \n",
       "11                         On the Night of the Fire   \n",
       "12                          The Three Weird Sisters   \n",
       "13                        The Curse of Frankenstein   \n",
       "14        The Hound of the Baskervilles (1959 film)   \n",
       "15                         Frankenstein (1931 film)   \n",
       "16             The House of the Seven Gables (film)   \n",
       "17                              Rebecca (1940 film)   \n",
       "18                          Dark Waters (1944 film)   \n",
       "19                            My Name Is Julia Ross   \n",
       "20                                  So Evil My Love   \n",
       "21                            Moonfleet (1955 film)   \n",
       "22                               Psycho (1960 film)   \n",
       "23                         The Beguiled (1971 film)   \n",
       "24                         A Handful of Dust (film)   \n",
       "25                            Jane Eyre (2011 film)   \n",
       "26                   The Woman in Black (2012 film)   \n",
       "27                                          Dracula   \n",
       "\n",
       "                                                Intro  \\\n",
       "0            Cross Creek               is a 1983 f...   \n",
       "1            Interview with the Vampire           ...   \n",
       "2            The Hunchback of Notre Dame          ...   \n",
       "3            Big Fish               is a 2003 Amer...   \n",
       "4            Lemony Snicket's A Series of Unfortun...   \n",
       "5            The Crow: Wicked Prayer              ...   \n",
       "6            Miracle at St. Anna               is ...   \n",
       "7            Beautiful Creatures               is ...   \n",
       "8            The Scribbler               is a 2014...   \n",
       "9            Crimson Peak               is a 2015 ...   \n",
       "10           The Beguiled               is a 2017 ...   \n",
       "11           On the Night of the Fire             ...   \n",
       "12           The Three Weird Sisters              ...   \n",
       "13           The Curse of Frankenstein            ...   \n",
       "14           The Hound of the Baskervilles        ...   \n",
       "15           Frankenstein               is a 1931 ...   \n",
       "16           The House of the Seven Gables        ...   \n",
       "17           Rebecca               is a 1940 Ameri...   \n",
       "18           Dark Waters               is a 1944  ...   \n",
       "19           My Name Is Julia Ross               i...   \n",
       "20           So Evil My Love               is a 19...   \n",
       "21           Moonfleet               is a 1955    ...   \n",
       "22           Psycho               is a 1960 Americ...   \n",
       "23           The Beguiled               is a 1971 ...   \n",
       "24           A Handful of Dust               is a ...   \n",
       "25           Jane Eyre               is a 2011 Bri...   \n",
       "26           The Woman in Black               is a...   \n",
       "27           Dracula               is an 1897     ...   \n",
       "\n",
       "                                                  Url  \n",
       "0    https://en.wikipedia.org/wiki/Cross_Creek_(film)  \n",
       "1   https://en.wikipedia.org/wiki/Interview_with_t...  \n",
       "2   https://en.wikipedia.org/wiki/The_Hunchback_of...  \n",
       "3              https://en.wikipedia.org/wiki/Big_Fish  \n",
       "4   https://en.wikipedia.org/wiki/Lemony_Snicket%2...  \n",
       "5   https://en.wikipedia.org/wiki/The_Crow:_Wicked...  \n",
       "6   https://en.wikipedia.org/wiki/Miracle_at_St._Anna  \n",
       "7   https://en.wikipedia.org/wiki/Beautiful_Creatu...  \n",
       "8   https://en.wikipedia.org/wiki/The_Scribbler_(f...  \n",
       "9          https://en.wikipedia.org/wiki/Crimson_Peak  \n",
       "10  https://en.wikipedia.org/wiki/The_Beguiled_(20...  \n",
       "11  https://en.wikipedia.org/wiki/On_the_Night_of_...  \n",
       "12  https://en.wikipedia.org/wiki/The_Three_Weird_...  \n",
       "13  https://en.wikipedia.org/wiki/The_Curse_of_Fra...  \n",
       "14  https://en.wikipedia.org/wiki/The_Hound_of_the...  \n",
       "15  https://en.wikipedia.org/wiki/Frankenstein_(19...  \n",
       "16  https://en.wikipedia.org/wiki/The_House_of_the...  \n",
       "17  https://en.wikipedia.org/wiki/Rebecca_(1940_film)  \n",
       "18  https://en.wikipedia.org/wiki/Dark_Waters_(194...  \n",
       "19  https://en.wikipedia.org/wiki/My_Name_Is_Julia...  \n",
       "20      https://en.wikipedia.org/wiki/So_Evil_My_Love  \n",
       "21  https://en.wikipedia.org/wiki/Moonfleet_(1955_...  \n",
       "22   https://en.wikipedia.org/wiki/Psycho_(1960_film)  \n",
       "23  https://en.wikipedia.org/wiki/The_Beguiled_(19...  \n",
       "24  https://en.wikipedia.org/wiki/A_Handful_of_Dus...  \n",
       "25  https://en.wikipedia.org/wiki/Jane_Eyre_(2011_...  \n",
       "26  https://en.wikipedia.org/wiki/The_Woman_in_Bla...  \n",
       "27              https://en.wikipedia.org/wiki/Dracula  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#HERE i DEFINE THE FUCTION TO RECEIVE THE DATASET, GIVEN AN INPUT\n",
    "y = list(input().split())\n",
    "def searchengine1(y):\n",
    "    for i in range(len(y)):\n",
    "        y[i]= preprocess(str(y[i]))\n",
    "    #Now I tranform the list of input in a list of the codes in the dictiionary based on the input\n",
    "    yfinal=[] #use this because some words have no match in the vocabulary\n",
    "    for i in range(len(y)):\n",
    "        #print(y[i])\n",
    "        if y[i] in diction:\n",
    "            yfinal.append(diction[y[i]])\n",
    "    #Now I have to search inside the lists of values from the keys i foundb and see if some films match in the various keys.\n",
    "    if  len(yfinal)<len(y):\n",
    "        return print('We are sorry there are no films, in my database, that match ALL the words you gave me !(')\n",
    "    else:\n",
    "        starting_values = diction2[yfinal[0]]\n",
    "        final_values = starting_values.copy()\n",
    "        for codes in range(1,len(yfinal)):\n",
    "            new = []\n",
    "            #print(final_values)\n",
    "            for film in final_values:                \n",
    "                if film in diction2[yfinal[codes]]:\n",
    "                    new.append(film)\n",
    "            final_values = new\n",
    "            #print(final_values)\n",
    "        megaDataframe = pd.DataFrame(columns = ['Title', 'Intro', 'Url'])\n",
    "        if not final_values:\n",
    "            return print(\"Wow no film matched my quiery, I need more films to compare!\")\n",
    "        else:           \n",
    "            k=0\n",
    "            for document in final_values:\n",
    "                totakeurl = document.replace('Cleantsv/filmclean-','')\n",
    "                totakeurl = str(int(totakeurl.replace('.tsv', '')))\n",
    "                url = dicturls[totakeurl]\n",
    "                temporary = pd.read_csv('Tsvfiles/'+'film'+(totakeurl)+'.tsv',delimiter='\\t' )\n",
    "                title = temporary['title'][0]\n",
    "                intro =  temporary['intro'][0].replace('\\r\\n','')\n",
    "                new_row = [title, intro, url]\n",
    "                megaDataframe.loc[k]=new_row\n",
    "                k=k+1\n",
    "            return megaDataframe\n",
    "A = searchengine1(y)\n",
    "A\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "daniel craig\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Intro</th>\n",
       "      <th>Url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Turner &amp; Hooch</td>\n",
       "      <td>Turner &amp; Hooch               is a 198...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Turner_%26_Hooch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Power of One (film)</td>\n",
       "      <td>The Power of One               is a 1...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Power_of_One...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101 Dalmatians (1996 film)</td>\n",
       "      <td>101 Dalmatians               is a 199...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/101_Dalmatians_(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Twisted Desire</td>\n",
       "      <td>Twisted Desire               is a 199...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Twisted_Desire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Thirteenth Floor</td>\n",
       "      <td>The Thirteenth Floor               is...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Thirteenth_F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lara Croft: Tomb Raider</td>\n",
       "      <td>Lara Croft: Tomb Raider              ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Lara_Croft:_Tomb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Road to Perdition</td>\n",
       "      <td>Road to Perdition               is a ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Road_to_Perdition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Casino Royale (2006 film)</td>\n",
       "      <td>Casino Royale               is a 2006...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Casino_Royale_(2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Infamous (film)</td>\n",
       "      <td>Infamous               is a 2006 Amer...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Infamous_(film)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The Golden Compass (film)</td>\n",
       "      <td>The Golden Compass               is a...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Golden_Compa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>The Invasion (film)</td>\n",
       "      <td>The Invasion               is a 2007 ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Invasion_(film)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Defiance (2008 film)</td>\n",
       "      <td>Defiance               is a 2008 Amer...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Defiance_(2008_f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Quantum of Solace</td>\n",
       "      <td>Quantum of Solace               is a ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Quantum_of_Solace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>The Adventures of Tintin (film)</td>\n",
       "      <td>The Adventures of Tintin             ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Adventures_o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Cowboys &amp; Aliens</td>\n",
       "      <td>Cowboys &amp; Aliens               is a 2...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Cowboys_%26_Aliens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Dream House (2011 film)</td>\n",
       "      <td>Dream House               is a 2011 A...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Dream_House_(201...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>The Girl with the Dragon Tattoo (2011 film)</td>\n",
       "      <td>The Girl with the Dragon Tattoo      ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Girl_with_th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Compliance (film)</td>\n",
       "      <td>Compliance               is a 2012 Am...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Compliance_(film)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Identity Thief</td>\n",
       "      <td>Identity Thief               is a 201...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Identity_Thief</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Snitch (film)</td>\n",
       "      <td>Snitch               is a 2013 Americ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Snitch_(film)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>The Longest Ride (film)</td>\n",
       "      <td>The Longest Ride               is a 2...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Longest_Ride...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>The Finest Hours (2016 film)</td>\n",
       "      <td>The Finest Hours               is a 2...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Finest_Hours...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Logan Lucky</td>\n",
       "      <td>Logan Lucky               is a 2017 A...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Logan_Lucky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>No Time to Die</td>\n",
       "      <td>No Time to Die               is an up...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/No_Time_to_Die</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>I Take This Oath</td>\n",
       "      <td>I Take This Oath               is a 1...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/I_Take_This_Oath</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>The Devil and Daniel Webster (film)</td>\n",
       "      <td>The Devil and Daniel Webster         ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Devil_and_Da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Dangerous Passage</td>\n",
       "      <td>Dangerous Passage               is a ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Dangerous_Passage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Beyond Glory</td>\n",
       "      <td>Beyond Glory               is a 1948 ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Beyond_Glory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Hit the Deck (1955 film)</td>\n",
       "      <td>Hit the Deck               is a 1955 ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Hit_the_Deck_(19...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>The Dunwich Horror (film)</td>\n",
       "      <td>The Dunwich Horror               is a...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Dunwich_Horr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Some Voices (film)</td>\n",
       "      <td>Some Voices               is a 2000 B...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Some_Voices_(film)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>The Mother (film)</td>\n",
       "      <td>The Mother               is a 2003 Br...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Mother_(film)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Sylvia (2003 film)</td>\n",
       "      <td>Sylvia               is a 2003 Britis...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Sylvia_(2003_film)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Enduring Love (film)</td>\n",
       "      <td>Enduring Love               is a 2004...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Enduring_Love_(f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Layer Cake (film)</td>\n",
       "      <td>Layer Cake               (also occasi...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Layer_Cake_(film)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Death at a Funeral (2007 film)</td>\n",
       "      <td>Death at a Funeral               is a...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Death_at_a_Funer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Flashbacks of a Fool</td>\n",
       "      <td>Flashbacks of a Fool               is...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Flashbacks_of_a_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Skyfall</td>\n",
       "      <td>Skyfall               is a 2012 Briti...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Skyfall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Spectre (2015 film)</td>\n",
       "      <td>Spectre               is a 2015 Briti...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Spectre_(2015_film)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Title  \\\n",
       "0                                Turner & Hooch   \n",
       "1                       The Power of One (film)   \n",
       "2                    101 Dalmatians (1996 film)   \n",
       "3                                Twisted Desire   \n",
       "4                          The Thirteenth Floor   \n",
       "5                       Lara Croft: Tomb Raider   \n",
       "6                             Road to Perdition   \n",
       "7                     Casino Royale (2006 film)   \n",
       "8                               Infamous (film)   \n",
       "9                     The Golden Compass (film)   \n",
       "10                          The Invasion (film)   \n",
       "11                         Defiance (2008 film)   \n",
       "12                            Quantum of Solace   \n",
       "13              The Adventures of Tintin (film)   \n",
       "14                             Cowboys & Aliens   \n",
       "15                      Dream House (2011 film)   \n",
       "16  The Girl with the Dragon Tattoo (2011 film)   \n",
       "17                            Compliance (film)   \n",
       "18                               Identity Thief   \n",
       "19                                Snitch (film)   \n",
       "20                      The Longest Ride (film)   \n",
       "21                 The Finest Hours (2016 film)   \n",
       "22                                  Logan Lucky   \n",
       "23                               No Time to Die   \n",
       "24                             I Take This Oath   \n",
       "25          The Devil and Daniel Webster (film)   \n",
       "26                            Dangerous Passage   \n",
       "27                                 Beyond Glory   \n",
       "28                     Hit the Deck (1955 film)   \n",
       "29                    The Dunwich Horror (film)   \n",
       "30                           Some Voices (film)   \n",
       "31                            The Mother (film)   \n",
       "32                           Sylvia (2003 film)   \n",
       "33                         Enduring Love (film)   \n",
       "34                            Layer Cake (film)   \n",
       "35               Death at a Funeral (2007 film)   \n",
       "36                         Flashbacks of a Fool   \n",
       "37                                      Skyfall   \n",
       "38                          Spectre (2015 film)   \n",
       "\n",
       "                                                Intro  \\\n",
       "0            Turner & Hooch               is a 198...   \n",
       "1            The Power of One               is a 1...   \n",
       "2            101 Dalmatians               is a 199...   \n",
       "3            Twisted Desire               is a 199...   \n",
       "4            The Thirteenth Floor               is...   \n",
       "5            Lara Croft: Tomb Raider              ...   \n",
       "6            Road to Perdition               is a ...   \n",
       "7            Casino Royale               is a 2006...   \n",
       "8            Infamous               is a 2006 Amer...   \n",
       "9            The Golden Compass               is a...   \n",
       "10           The Invasion               is a 2007 ...   \n",
       "11           Defiance               is a 2008 Amer...   \n",
       "12           Quantum of Solace               is a ...   \n",
       "13           The Adventures of Tintin             ...   \n",
       "14           Cowboys & Aliens               is a 2...   \n",
       "15           Dream House               is a 2011 A...   \n",
       "16           The Girl with the Dragon Tattoo      ...   \n",
       "17           Compliance               is a 2012 Am...   \n",
       "18           Identity Thief               is a 201...   \n",
       "19           Snitch               is a 2013 Americ...   \n",
       "20           The Longest Ride               is a 2...   \n",
       "21           The Finest Hours               is a 2...   \n",
       "22           Logan Lucky               is a 2017 A...   \n",
       "23           No Time to Die               is an up...   \n",
       "24           I Take This Oath               is a 1...   \n",
       "25           The Devil and Daniel Webster         ...   \n",
       "26           Dangerous Passage               is a ...   \n",
       "27           Beyond Glory               is a 1948 ...   \n",
       "28           Hit the Deck               is a 1955 ...   \n",
       "29           The Dunwich Horror               is a...   \n",
       "30           Some Voices               is a 2000 B...   \n",
       "31           The Mother               is a 2003 Br...   \n",
       "32           Sylvia               is a 2003 Britis...   \n",
       "33           Enduring Love               is a 2004...   \n",
       "34           Layer Cake               (also occasi...   \n",
       "35           Death at a Funeral               is a...   \n",
       "36           Flashbacks of a Fool               is...   \n",
       "37           Skyfall               is a 2012 Briti...   \n",
       "38           Spectre               is a 2015 Briti...   \n",
       "\n",
       "                                                  Url  \n",
       "0      https://en.wikipedia.org/wiki/Turner_%26_Hooch  \n",
       "1   https://en.wikipedia.org/wiki/The_Power_of_One...  \n",
       "2   https://en.wikipedia.org/wiki/101_Dalmatians_(...  \n",
       "3        https://en.wikipedia.org/wiki/Twisted_Desire  \n",
       "4   https://en.wikipedia.org/wiki/The_Thirteenth_F...  \n",
       "5   https://en.wikipedia.org/wiki/Lara_Croft:_Tomb...  \n",
       "6     https://en.wikipedia.org/wiki/Road_to_Perdition  \n",
       "7   https://en.wikipedia.org/wiki/Casino_Royale_(2...  \n",
       "8       https://en.wikipedia.org/wiki/Infamous_(film)  \n",
       "9   https://en.wikipedia.org/wiki/The_Golden_Compa...  \n",
       "10  https://en.wikipedia.org/wiki/The_Invasion_(film)  \n",
       "11  https://en.wikipedia.org/wiki/Defiance_(2008_f...  \n",
       "12    https://en.wikipedia.org/wiki/Quantum_of_Solace  \n",
       "13  https://en.wikipedia.org/wiki/The_Adventures_o...  \n",
       "14   https://en.wikipedia.org/wiki/Cowboys_%26_Aliens  \n",
       "15  https://en.wikipedia.org/wiki/Dream_House_(201...  \n",
       "16  https://en.wikipedia.org/wiki/The_Girl_with_th...  \n",
       "17    https://en.wikipedia.org/wiki/Compliance_(film)  \n",
       "18       https://en.wikipedia.org/wiki/Identity_Thief  \n",
       "19        https://en.wikipedia.org/wiki/Snitch_(film)  \n",
       "20  https://en.wikipedia.org/wiki/The_Longest_Ride...  \n",
       "21  https://en.wikipedia.org/wiki/The_Finest_Hours...  \n",
       "22          https://en.wikipedia.org/wiki/Logan_Lucky  \n",
       "23       https://en.wikipedia.org/wiki/No_Time_to_Die  \n",
       "24     https://en.wikipedia.org/wiki/I_Take_This_Oath  \n",
       "25  https://en.wikipedia.org/wiki/The_Devil_and_Da...  \n",
       "26    https://en.wikipedia.org/wiki/Dangerous_Passage  \n",
       "27         https://en.wikipedia.org/wiki/Beyond_Glory  \n",
       "28  https://en.wikipedia.org/wiki/Hit_the_Deck_(19...  \n",
       "29  https://en.wikipedia.org/wiki/The_Dunwich_Horr...  \n",
       "30   https://en.wikipedia.org/wiki/Some_Voices_(film)  \n",
       "31    https://en.wikipedia.org/wiki/The_Mother_(film)  \n",
       "32   https://en.wikipedia.org/wiki/Sylvia_(2003_film)  \n",
       "33  https://en.wikipedia.org/wiki/Enduring_Love_(f...  \n",
       "34    https://en.wikipedia.org/wiki/Layer_Cake_(film)  \n",
       "35  https://en.wikipedia.org/wiki/Death_at_a_Funer...  \n",
       "36  https://en.wikipedia.org/wiki/Flashbacks_of_a_...  \n",
       "37              https://en.wikipedia.org/wiki/Skyfall  \n",
       "38  https://en.wikipedia.org/wiki/Spectre_(2015_film)  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = list(input().split())\n",
    "searchengine1(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gothic film novel\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'searchengine1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-84-483cada9b73b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0msearchengine1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'searchengine1' is not defined"
     ]
    }
   ],
   "source": [
    "y = list(input().split())\n",
    "searchengine1(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2) Conjunctive query & Ranking score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building of the second search engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we create a list with inside strings that represent intro and plot of every document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Docum_and_words = []\n",
    "for i in range(30000):\n",
    "    file = \"Cleantsv/filmclean-\"+str(i)+'.tsv'\n",
    "    file1 = open(file, encoding=\"utf8\") \n",
    "    line = file1.read()# Use this to read file content as a stream: \n",
    "    #print(line)\n",
    "    words = line.split('\\t') \n",
    "    wordssplitted1 = words[14].split()\n",
    "    wordssplitted2 = words[15].split()\n",
    "    words = wordssplitted1+wordssplitted2\n",
    "    A = \" \".join(words)\n",
    "    Docum_and_words.append(A)\n",
    "#print(Docum_and_words) \n",
    "#I have the lis of documents with intro and plot\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define two function to get the tf and the number of documents containing a word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from textblob import TextBlob as tb\n",
    "def tf(word, doc):\n",
    "    return doc.count(word) / len(doc)\n",
    "\n",
    "def n_containing(word, doclist):\n",
    "    return sum(1 for doc in doclist if word in doc.split())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create dictionary with idf to save computational costs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Third dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some preliminary declarations to run the code at any moment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "Docum_and_words = []\n",
    "for i in range(30000):\n",
    "    file = \"Cleantsv/filmclean-\"+str(i)+'.tsv'\n",
    "    file1 = open(file, encoding=\"utf8\") \n",
    "    line = file1.read()\n",
    "    words = line.split('\\t') \n",
    "    wordssplitted1 = words[14].split()\n",
    "    wordssplitted2 = words[15].split()\n",
    "    words = wordssplitted1+wordssplitted2\n",
    "    A = \" \".join(words)\n",
    "    Docum_and_words.append(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'10 midnight 1983 american crime horror thriller film 3 direct j lee thompson screenplay origin written william robert film star charl bronson lead role support cast includ lisa eilbach andrew steven gene davi geoffrey lewi wilford brimley 10 midnight releas citi film subsidiari cannon film american cinema march 11 1983 warren staci gene davi young offic equip repairman kill women reject sexual advanc attempt flirt alway seen creepi women result frequent reject 4 first victim betti june gilbert offic worker acquaint track wood area observ sex boyfriend ambush coupl kill boyfriend give chase nake woman catch stab death 4 two lo angel polic detect leo kessler charl bronson paul mcann andrew steven investig murder kessler season veteran forc mcann consider younger 4 staci avoid prosecut construct sound alibi assault victim nake except pair latex glove hide fingerprint thu minim evid lauri kessler lisa eilbach daughter leo acquaint victim student nurs becom target killer 4 mcann refus go along kessler plant evid order frame suspect staci goe anoth rampag kill three nurs student friend kessler daughter eventu caught stark nake street staci boast say thing prove crazi hear voic order thing etc one day back street kessler well whole fuck world hear kessler repli shoot staci forehead execut leav consider asid kessler stand bodi surround polic'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Docum_and_words[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"C:\\Users\\leona\\Desktop\\ADMHMK-3\\dicturls.json\", 'r') as file:\n",
    "    data = file.read()\n",
    "dicturls = json.loads(data) \n",
    "with open(r\"C:\\Users\\leona\\Desktop\\ADMHMK-3\\Dictionary.json\", 'r') as file:\n",
    "    data = file.read()\n",
    "diction = json.loads(data) #first dict with every word and a unique value\n",
    "with open(r\"C:\\Users\\leona\\Desktop\\ADMHMK-3\\Dictionary1.json\", 'r') as file:\n",
    "    data = file.read()\n",
    "diction2 = json.loads(data)#first inverted dict with number and list of document with a word that has that number in diction\n",
    "import math\n",
    "from textblob import TextBlob as tb\n",
    "def tf(word, doc):\n",
    "    return doc.count(word) / len(doc)\n",
    "def n_containing(word, doclist):\n",
    "    return sum(1 for doc in doclist if word in doc.split())\n",
    "\n",
    "def idf(word, doclist):\n",
    "    return math.log(len(doclist) / float(n_containing(word, doclist)))\n",
    "\n",
    "def tfidf(word, doc, doclist):\n",
    "    return (tf(word, doc) * idf(word, doclist))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a dictionary with inside associated to every word in diction(the one that matched indexes and words) the number of documents it is in on the 30.000 of the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncontain = {}\n",
    "for i in diction:\n",
    "    refer = diction[i]\n",
    "    #print(i)\n",
    "    ncontain[i] = len(diction2[refer])\n",
    "with open('ncontain.json', 'w') as fp:\n",
    "    json.dump(ncontain, fp)\n",
    "with open(r\"C:\\Users\\leona\\Desktop\\ADMHMK-3\\ncontain.json\", 'r') as file:\n",
    "    data = file.read()\n",
    "ncontain = json.loads(data) #first dict with every word and a unique value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114796"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ncontain.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "idfdict is the dictionary that if you select a word will give you its idf. We save it as a json file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "idfdict = {}\n",
    "for i in ncontain:\n",
    "    idfdict[i]=math.log(30000 / ncontain[i])\n",
    "with open('idfdict.json', 'w') as fp:\n",
    "    json.dump(idfdict, fp)\n",
    "with open(r\"C:\\Users\\leona\\Desktop\\ADMHMK-3\\idfdict.json\", 'r') as file:\n",
    "    data = file.read()\n",
    "idfdict = json.loads(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"C:\\Users\\leona\\Desktop\\ADMHMK-3\\idfdict.json\", 'r') as file:\n",
    "    data = file.read()\n",
    "idfdict = json.loads(data)\n",
    "#idfdict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2.1) Inverted index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second dictionary with the tf-idf values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are ready to do very easily the dictionary with key : ([document, tf-idf]) because we already saved the idf in a dictioonary so the next code will be pretty fast in creating the dict. We save it a json file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dictionar3 = {}\n",
    "#length = 0\n",
    "for i in range(30000):\n",
    "    file = \"Cleantsv/filmclean-\"+str(i)+'.tsv'\n",
    "    temp = []\n",
    "    for j in Docum_and_words[i].split():\n",
    "            if j not in temp:\n",
    "                #dicus = {}\n",
    "                code = diction[j]\n",
    "                value = tf(j, Docum_and_words[i].split())*idfdict[j]\n",
    "                li = [file, value]\n",
    "                if code not in dictionar3:\n",
    "                    #dicus[file]=value\n",
    "                    dictionar3[code] = [li]\n",
    "                else:   \n",
    "                    #dicus[file]=value\n",
    "                    dictionar3[code].append(li)\n",
    "                temp.append(j)\n",
    "import json\n",
    "\n",
    "with open('Dictionary2.json', 'w') as fp:\n",
    "    json.dump(dictionar3, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114796"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dictionar3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now I import the files I need and prepare the code for the search engine2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "with open(r\"C:\\Users\\leona\\Desktop\\ADMHMK-3\\dicturls.json\", 'r') as file:\n",
    "    data = file.read()\n",
    "dicturls = json.loads(data) \n",
    "with open(r\"C:\\Users\\leona\\Desktop\\ADMHMK-3\\Dictionary.json\", 'r') as file:\n",
    "    data = file.read()\n",
    "diction = json.loads(data) #first dict with every word and a unique value\n",
    "with open(r\"C:\\Users\\leona\\Desktop\\ADMHMK-3\\Dictionary1.json\", 'r') as file:\n",
    "    data = file.read()\n",
    "diction2 = json.loads(data)#first inverted dict with number and list of document with a word that has that number in diction\n",
    "with open(r\"C:\\Users\\leona\\Desktop\\ADMHMK-3\\ncontain.json\", 'r') as file:\n",
    "    data = file.read()\n",
    "ncontain = json.loads(data) #dict with number of times a word appear in all the cod\n",
    "with open(r\"C:\\Users\\leona\\Desktop\\ADMHMK-3\\idfdict.json\", 'r') as file:\n",
    "    data = file.read()\n",
    "idfdict = json.loads(data) #dict with the idf for every word\n",
    "with open(r\"C:\\Users\\leona\\Desktop\\ADMHMK-3\\Dictionary2.json\", 'r') as file:\n",
    "    data = file.read()\n",
    "diction3 = json.loads(data) #second inverted dictionary wit doc and tfidf for eevry word\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ASbout copsine similarity I have to take the tfidf of my k best document and multipèly singularly it with the values of the quiery that are tf(relative of the quiery)*idf(relative to my documents for each component)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The query entered by the user can also be represented as a vector. We will calculate the TF*IDF for the query\n",
    "\n",
    "TF\tIDF\tTF*IDF\n",
    "life\t0.5\t1.405507153\t0.702753576\n",
    "learning\t0.5\t1.405507153\t0.702753576\n",
    "Let us now calculate the cosine similarity of the query and Document1. You can do the calculation using this tool.\n",
    "\n",
    "Cosine Similarity(Query,Document1) = Dot product(Query, Document1) / ||Query|| * ||Document1||\n",
    "\n",
    "Dot product(Query, Document1) \n",
    "     = ((0.702753576) * (0.140550715) + (0.702753576)*(0.140550715))\n",
    "     = 0.197545035151\n",
    "\n",
    "||Query|| = sqrt((0.702753576)2 + (0.702753576)2) = 0.993843638185\n",
    "\n",
    "||Document1|| = sqrt((0.140550715)2 + (0.140550715)2) = 0.198768727354\n",
    "\n",
    "Cosine Similarity(Query, Document) = 0.197545035151 / (0.993843638185) * (0.198768727354)\n",
    "                                        = 0.197545035151 / 0.197545035151\n",
    "                                        = 1\n",
    "        \n",
    "https://janav.wordpress.com/2013/10/27/tf-idf-and-cosine-similarity/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I prepare the code for the search engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here there are the functions to easily compute the cosine similarity given two vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as pyplot\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "def simple_dot(a, b):\n",
    "    dsum = 0.\n",
    "    for ((idx,), val) in np.ndenumerate(a):\n",
    "        dsum += float(val) * float(b[idx])\n",
    "    return dsum\n",
    "\n",
    "def l2_norm(a):\n",
    "    return math.sqrt(np.dot(a, a))\n",
    "\n",
    "def cosine_similarity(a, b):\n",
    "    return np.dot(a,b) / (l2_norm(a)* l2_norm(b))\n",
    "np.dot([1,2],[3,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I remind that Docume_and_words is a list with inside every intro-plot(preprocessed) for every document, so I can just accees to it for my research."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "Docum_and_words = []\n",
    "for i in range(30000):\n",
    "    file = \"Cleantsv/filmclean-\"+str(i)+'.tsv'\n",
    "    file1 = open(file, encoding=\"utf8\") \n",
    "    line = file1.read()\n",
    "    words = line.split('\\t') \n",
    "    wordssplitted1 = words[14].split()\n",
    "    wordssplitted2 = words[15].split()\n",
    "    words = wordssplitted1+wordssplitted2\n",
    "    A = \" \".join(words)\n",
    "    Docum_and_words.append(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io \n",
    "import nltk\n",
    "import csv\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    "stop_words = set(stopwords.words('english')) \n",
    "from nltk.stem import PorterStemmer \n",
    "\n",
    " \n",
    "ps = PorterStemmer() \n",
    "#the fuction preprocess the string as asked in the hmk\n",
    "def preprocess(sentence):\n",
    "    sentence = sentence.lower()\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokens = tokenizer.tokenize(sentence)\n",
    "    filtered_words = [ps.stem(w) for w in tokens if not w in stopwords.words('english')]\n",
    "    return \" \".join(filtered_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2.2) Execute the query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ENGINE2!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I build the search engine2. The heap sorting is in the 'cossim' list that will have all the possible values of cosine similarity we have found for the query. We will print the dataframe with the best 20 results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gothic film novel\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Intro</th>\n",
       "      <th>Url</th>\n",
       "      <th>Similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dark Waters (1944 film)</td>\n",
       "      <td>Dark Waters               is a 1944  ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Dark_Waters_(194...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>My Name Is Julia Ross</td>\n",
       "      <td>My Name Is Julia Ross               i...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/My_Name_Is_Julia...</td>\n",
       "      <td>0.9999897486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Beguiled (1971 film)</td>\n",
       "      <td>The Beguiled               is a 1971 ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Beguiled_(19...</td>\n",
       "      <td>0.9999897486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Scribbler (film)</td>\n",
       "      <td>The Scribbler               is a 2014...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Scribbler_(f...</td>\n",
       "      <td>0.9999897486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Moonfleet (1955 film)</td>\n",
       "      <td>Moonfleet               is a 1955    ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Moonfleet_(1955_...</td>\n",
       "      <td>0.999958998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The Crow: Wicked Prayer</td>\n",
       "      <td>The Crow: Wicked Prayer              ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Crow:_Wicked...</td>\n",
       "      <td>0.999958998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Beautiful Creatures (2013 film)</td>\n",
       "      <td>Beautiful Creatures               is ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Beautiful_Creatu...</td>\n",
       "      <td>0.999958998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Jane Eyre (2011 film)</td>\n",
       "      <td>Jane Eyre               is a 2011 Bri...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Jane_Eyre_(2011_...</td>\n",
       "      <td>0.9999077563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The Three Weird Sisters</td>\n",
       "      <td>The Three Weird Sisters              ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Three_Weird_...</td>\n",
       "      <td>0.9999077563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>So Evil My Love</td>\n",
       "      <td>So Evil My Love               is a 19...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/So_Evil_My_Love</td>\n",
       "      <td>0.9999077563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Interview with the Vampire (film)</td>\n",
       "      <td>Interview with the Vampire           ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Interview_with_t...</td>\n",
       "      <td>0.9998360356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>The Curse of Frankenstein</td>\n",
       "      <td>The Curse of Frankenstein            ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Curse_of_Fra...</td>\n",
       "      <td>0.9998360356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Frankenstein (1931 film)</td>\n",
       "      <td>Frankenstein               is a 1931 ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Frankenstein_(19...</td>\n",
       "      <td>0.9997438516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Lemony Snicket's A Series of Unfortunate Events</td>\n",
       "      <td>Lemony Snicket's A Series of Unfortun...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Lemony_Snicket%2...</td>\n",
       "      <td>0.9996312237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>On the Night of the Fire</td>\n",
       "      <td>On the Night of the Fire             ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/On_the_Night_of_...</td>\n",
       "      <td>0.9996312237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Rebecca (1940 film)</td>\n",
       "      <td>Rebecca               is a 1940 Ameri...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Rebecca_(1940_film)</td>\n",
       "      <td>0.9994981753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>The Hunchback of Notre Dame (1996 film)</td>\n",
       "      <td>The Hunchback of Notre Dame          ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Hunchback_of...</td>\n",
       "      <td>0.9991709284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Psycho (1960 film)</td>\n",
       "      <td>Psycho               is a 1960 Americ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Psycho_(1960_film)</td>\n",
       "      <td>0.9987623716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Crimson Peak</td>\n",
       "      <td>Crimson Peak               is a 2015 ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Crimson_Peak</td>\n",
       "      <td>0.9799744419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>A Handful of Dust (film)</td>\n",
       "      <td>A Handful of Dust               is a ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/A_Handful_of_Dus...</td>\n",
       "      <td>0.9672200926</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Title  \\\n",
       "0                           Dark Waters (1944 film)   \n",
       "1                             My Name Is Julia Ross   \n",
       "2                          The Beguiled (1971 film)   \n",
       "3                              The Scribbler (film)   \n",
       "4                             Moonfleet (1955 film)   \n",
       "5                           The Crow: Wicked Prayer   \n",
       "6                   Beautiful Creatures (2013 film)   \n",
       "7                             Jane Eyre (2011 film)   \n",
       "8                           The Three Weird Sisters   \n",
       "9                                   So Evil My Love   \n",
       "10                Interview with the Vampire (film)   \n",
       "11                        The Curse of Frankenstein   \n",
       "12                         Frankenstein (1931 film)   \n",
       "13  Lemony Snicket's A Series of Unfortunate Events   \n",
       "14                         On the Night of the Fire   \n",
       "15                              Rebecca (1940 film)   \n",
       "16          The Hunchback of Notre Dame (1996 film)   \n",
       "17                               Psycho (1960 film)   \n",
       "18                                     Crimson Peak   \n",
       "19                         A Handful of Dust (film)   \n",
       "\n",
       "                                                Intro  \\\n",
       "0            Dark Waters               is a 1944  ...   \n",
       "1            My Name Is Julia Ross               i...   \n",
       "2            The Beguiled               is a 1971 ...   \n",
       "3            The Scribbler               is a 2014...   \n",
       "4            Moonfleet               is a 1955    ...   \n",
       "5            The Crow: Wicked Prayer              ...   \n",
       "6            Beautiful Creatures               is ...   \n",
       "7            Jane Eyre               is a 2011 Bri...   \n",
       "8            The Three Weird Sisters              ...   \n",
       "9            So Evil My Love               is a 19...   \n",
       "10           Interview with the Vampire           ...   \n",
       "11           The Curse of Frankenstein            ...   \n",
       "12           Frankenstein               is a 1931 ...   \n",
       "13           Lemony Snicket's A Series of Unfortun...   \n",
       "14           On the Night of the Fire             ...   \n",
       "15           Rebecca               is a 1940 Ameri...   \n",
       "16           The Hunchback of Notre Dame          ...   \n",
       "17           Psycho               is a 1960 Americ...   \n",
       "18           Crimson Peak               is a 2015 ...   \n",
       "19           A Handful of Dust               is a ...   \n",
       "\n",
       "                                                  Url    Similarity  \n",
       "0   https://en.wikipedia.org/wiki/Dark_Waters_(194...             1  \n",
       "1   https://en.wikipedia.org/wiki/My_Name_Is_Julia...  0.9999897486  \n",
       "2   https://en.wikipedia.org/wiki/The_Beguiled_(19...  0.9999897486  \n",
       "3   https://en.wikipedia.org/wiki/The_Scribbler_(f...  0.9999897486  \n",
       "4   https://en.wikipedia.org/wiki/Moonfleet_(1955_...   0.999958998  \n",
       "5   https://en.wikipedia.org/wiki/The_Crow:_Wicked...   0.999958998  \n",
       "6   https://en.wikipedia.org/wiki/Beautiful_Creatu...   0.999958998  \n",
       "7   https://en.wikipedia.org/wiki/Jane_Eyre_(2011_...  0.9999077563  \n",
       "8   https://en.wikipedia.org/wiki/The_Three_Weird_...  0.9999077563  \n",
       "9       https://en.wikipedia.org/wiki/So_Evil_My_Love  0.9999077563  \n",
       "10  https://en.wikipedia.org/wiki/Interview_with_t...  0.9998360356  \n",
       "11  https://en.wikipedia.org/wiki/The_Curse_of_Fra...  0.9998360356  \n",
       "12  https://en.wikipedia.org/wiki/Frankenstein_(19...  0.9997438516  \n",
       "13  https://en.wikipedia.org/wiki/Lemony_Snicket%2...  0.9996312237  \n",
       "14  https://en.wikipedia.org/wiki/On_the_Night_of_...  0.9996312237  \n",
       "15  https://en.wikipedia.org/wiki/Rebecca_(1940_film)  0.9994981753  \n",
       "16  https://en.wikipedia.org/wiki/The_Hunchback_of...  0.9991709284  \n",
       "17   https://en.wikipedia.org/wiki/Psycho_(1960_film)  0.9987623716  \n",
       "18         https://en.wikipedia.org/wiki/Crimson_Peak  0.9799744419  \n",
       "19  https://en.wikipedia.org/wiki/A_Handful_of_Dus...  0.9672200926  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#HERE i DEFINE THE FUCTION TO RECEIVE THE DATASET, GIVEN AN INPUT\n",
    "import heapq as hq\n",
    "def tf(word, doc):\n",
    "    return doc.count(word) / len(doc)\n",
    "y = list(input().split())\n",
    "def searchengine2(y):\n",
    "    for i in range(len(y)):\n",
    "        y[i]= preprocess(str(y[i]))\n",
    "    #Now I tranform the list of input in a list of the codes in the dictiionary based on the input\n",
    "    yfinal=[] #use this because some words have no match in the vocabulary\n",
    "    for i in range(len(y)):\n",
    "        #print(y[i])\n",
    "        if y[i] in diction:\n",
    "            yfinal.append(diction[y[i]])\n",
    "    #Now I have to search inside the lists of values from the keys i foundb and see if some films match in the various keys.\n",
    "    if  len(yfinal)<len(y):\n",
    "        return print('We are sorry there are no films, in my database, that match ALL the words you gave me !(')\n",
    "    else:\n",
    "        starting_values = diction2[yfinal[0]]\n",
    "        final_values = starting_values.copy()\n",
    "        for codes in range(1,len(yfinal)):\n",
    "            new = []\n",
    "            for film in final_values:\n",
    "                if film in diction2[yfinal[codes]]:\n",
    "                    new.append(film)\n",
    "            final_values = new\n",
    "        megaDataframe = pd.DataFrame(columns = ['Title', 'Intro', 'Url', 'Similarity'])\n",
    "        if not final_values:\n",
    "            return print(\"Wow no film matched my quiery, I need more films to compare!\")\n",
    "        else:  \n",
    "            lstofl = []\n",
    "            #here there is a lstofl that has vectors associated with every document, in order of final_values\n",
    "            for film in final_values:\n",
    "                item = []\n",
    "                for code in yfinal:\n",
    "                    for value in diction3[code]:\n",
    "                        if film in value:\n",
    "                            item.append(value[1])\n",
    "                            break\n",
    "                lstofl.append(item) \n",
    "            #print(lstofl)\n",
    "            #Now I have to create the inquiry vector and get the cosine similarity of beetween it and every component of lstofl \n",
    "            query = []\n",
    "            for i in y:\n",
    "                query.append(tf(i,y)*idfdict[i])\n",
    "            cossim = []\n",
    "            for vector in lstofl:\n",
    "                cossim.append(cosine_similarity(query, vector))\n",
    "            #print(cossim) #the cosine similariotyb in order of apparition of my document\n",
    "            dict_sim = {}\n",
    "            for indx in range(len(cossim)):\n",
    "                sim = cossim[indx]\n",
    "                if sim not in dict_sim:\n",
    "                    dict_sim[sim]=[final_values[indx]]\n",
    "                else:\n",
    "                    dict_sim[sim].append(final_values[indx])\n",
    "            #print(dict_sim)\n",
    "            Peak = 20\n",
    "            #HERE THE HEAP ALGORITHM\n",
    "            cossim = list(set(cossim))\n",
    "            to_select = hq.nlargest(Peak, cossim)   \n",
    "            k=0\n",
    "            #print(to_select)\n",
    "            #Now i have the name key(cossim) and values(docum) and I have to take the first 15 of them.\n",
    "            for i in to_select:\n",
    "                if(k<Peak):\n",
    "                    for document in dict_sim[i]:\n",
    "                            if(k>Peak):\n",
    "                                return megaDataframe\n",
    "                            totakeurl = document.replace('Cleantsv/filmclean-','')\n",
    "                            totakeurl = str(int(totakeurl.replace('.tsv', '')))\n",
    "                            url = dicturls[totakeurl]\n",
    "                            Similarity = format(i, '.10g')\n",
    "                            temporary = pd.read_csv('Tsvfiles/'+'film'+(totakeurl)+'.tsv',delimiter='\\t' )\n",
    "                            title = temporary['title'][0]\n",
    "                            intro =  temporary['intro'][0].replace('\\r\\n','')\n",
    "                            new_row = [title, intro, url, Similarity]\n",
    "                            megaDataframe.loc[k]=new_row\n",
    "                            k=k+1\n",
    "            return  megaDataframe\n",
    "A = searchengine2(y)\n",
    "A\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see some examples! As we use simple strings and with not many repetitions it's possible more than one value will be one, as we will put a more difficult query we will have lower similarity probably."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "craig 007\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Intro</th>\n",
       "      <th>Url</th>\n",
       "      <th>Similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Casino Royale (2006 film)</td>\n",
       "      <td>Casino Royale               is a 2006...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Casino_Royale_(2...</td>\n",
       "      <td>0.8660544238</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Title  \\\n",
       "0  Casino Royale (2006 film)   \n",
       "\n",
       "                                               Intro  \\\n",
       "0           Casino Royale               is a 2006...   \n",
       "\n",
       "                                                 Url    Similarity  \n",
       "0  https://en.wikipedia.org/wiki/Casino_Royale_(2...  0.8660544238  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = list(input().split())\n",
    "searchengine2(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "daniel craig\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Intro</th>\n",
       "      <th>Url</th>\n",
       "      <th>Similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Turner &amp; Hooch</td>\n",
       "      <td>Turner &amp; Hooch               is a 198...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Turner_%26_Hooch</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Road to Perdition</td>\n",
       "      <td>Road to Perdition               is a ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Road_to_Perdition</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Defiance (2008 film)</td>\n",
       "      <td>Defiance               is a 2008 Amer...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Defiance_(2008_f...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I Take This Oath</td>\n",
       "      <td>I Take This Oath               is a 1...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/I_Take_This_Oath</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dangerous Passage</td>\n",
       "      <td>Dangerous Passage               is a ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Dangerous_Passage</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sylvia (2003 film)</td>\n",
       "      <td>Sylvia               is a 2003 Britis...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Sylvia_(2003_film)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Layer Cake (film)</td>\n",
       "      <td>Layer Cake               (also occasi...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Layer_Cake_(film)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The Power of One (film)</td>\n",
       "      <td>The Power of One               is a 1...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Power_of_One...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>101 Dalmatians (1996 film)</td>\n",
       "      <td>101 Dalmatians               is a 199...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/101_Dalmatians_(...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The Thirteenth Floor</td>\n",
       "      <td>The Thirteenth Floor               is...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Thirteenth_F...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Lara Croft: Tomb Raider</td>\n",
       "      <td>Lara Croft: Tomb Raider              ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Lara_Croft:_Tomb...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>The Golden Compass (film)</td>\n",
       "      <td>The Golden Compass               is a...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Golden_Compa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>The Invasion (film)</td>\n",
       "      <td>The Invasion               is a 2007 ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Invasion_(film)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>The Adventures of Tintin (film)</td>\n",
       "      <td>The Adventures of Tintin             ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Adventures_o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Dream House (2011 film)</td>\n",
       "      <td>Dream House               is a 2011 A...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Dream_House_(201...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>The Finest Hours (2016 film)</td>\n",
       "      <td>The Finest Hours               is a 2...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Finest_Hours...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Logan Lucky</td>\n",
       "      <td>Logan Lucky               is a 2017 A...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Logan_Lucky</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>No Time to Die</td>\n",
       "      <td>No Time to Die               is an up...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/No_Time_to_Die</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Hit the Deck (1955 film)</td>\n",
       "      <td>Hit the Deck               is a 1955 ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Hit_the_Deck_(19...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>The Dunwich Horror (film)</td>\n",
       "      <td>The Dunwich Horror               is a...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Dunwich_Horr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Some Voices (film)</td>\n",
       "      <td>Some Voices               is a 2000 B...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Some_Voices_(film)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Title  \\\n",
       "0                    Turner & Hooch   \n",
       "1                 Road to Perdition   \n",
       "2              Defiance (2008 film)   \n",
       "3                  I Take This Oath   \n",
       "4                 Dangerous Passage   \n",
       "5                Sylvia (2003 film)   \n",
       "6                 Layer Cake (film)   \n",
       "7           The Power of One (film)   \n",
       "8        101 Dalmatians (1996 film)   \n",
       "9              The Thirteenth Floor   \n",
       "10          Lara Croft: Tomb Raider   \n",
       "11        The Golden Compass (film)   \n",
       "12              The Invasion (film)   \n",
       "13  The Adventures of Tintin (film)   \n",
       "14          Dream House (2011 film)   \n",
       "15     The Finest Hours (2016 film)   \n",
       "16                      Logan Lucky   \n",
       "17                   No Time to Die   \n",
       "18         Hit the Deck (1955 film)   \n",
       "19        The Dunwich Horror (film)   \n",
       "20               Some Voices (film)   \n",
       "\n",
       "                                                Intro  \\\n",
       "0            Turner & Hooch               is a 198...   \n",
       "1            Road to Perdition               is a ...   \n",
       "2            Defiance               is a 2008 Amer...   \n",
       "3            I Take This Oath               is a 1...   \n",
       "4            Dangerous Passage               is a ...   \n",
       "5            Sylvia               is a 2003 Britis...   \n",
       "6            Layer Cake               (also occasi...   \n",
       "7            The Power of One               is a 1...   \n",
       "8            101 Dalmatians               is a 199...   \n",
       "9            The Thirteenth Floor               is...   \n",
       "10           Lara Croft: Tomb Raider              ...   \n",
       "11           The Golden Compass               is a...   \n",
       "12           The Invasion               is a 2007 ...   \n",
       "13           The Adventures of Tintin             ...   \n",
       "14           Dream House               is a 2011 A...   \n",
       "15           The Finest Hours               is a 2...   \n",
       "16           Logan Lucky               is a 2017 A...   \n",
       "17           No Time to Die               is an up...   \n",
       "18           Hit the Deck               is a 1955 ...   \n",
       "19           The Dunwich Horror               is a...   \n",
       "20           Some Voices               is a 2000 B...   \n",
       "\n",
       "                                                  Url Similarity  \n",
       "0      https://en.wikipedia.org/wiki/Turner_%26_Hooch          1  \n",
       "1     https://en.wikipedia.org/wiki/Road_to_Perdition          1  \n",
       "2   https://en.wikipedia.org/wiki/Defiance_(2008_f...          1  \n",
       "3      https://en.wikipedia.org/wiki/I_Take_This_Oath          1  \n",
       "4     https://en.wikipedia.org/wiki/Dangerous_Passage          1  \n",
       "5    https://en.wikipedia.org/wiki/Sylvia_(2003_film)          1  \n",
       "6     https://en.wikipedia.org/wiki/Layer_Cake_(film)          1  \n",
       "7   https://en.wikipedia.org/wiki/The_Power_of_One...          1  \n",
       "8   https://en.wikipedia.org/wiki/101_Dalmatians_(...          1  \n",
       "9   https://en.wikipedia.org/wiki/The_Thirteenth_F...          1  \n",
       "10  https://en.wikipedia.org/wiki/Lara_Croft:_Tomb...          1  \n",
       "11  https://en.wikipedia.org/wiki/The_Golden_Compa...          1  \n",
       "12  https://en.wikipedia.org/wiki/The_Invasion_(film)          1  \n",
       "13  https://en.wikipedia.org/wiki/The_Adventures_o...          1  \n",
       "14  https://en.wikipedia.org/wiki/Dream_House_(201...          1  \n",
       "15  https://en.wikipedia.org/wiki/The_Finest_Hours...          1  \n",
       "16          https://en.wikipedia.org/wiki/Logan_Lucky          1  \n",
       "17       https://en.wikipedia.org/wiki/No_Time_to_Die          1  \n",
       "18  https://en.wikipedia.org/wiki/Hit_the_Deck_(19...          1  \n",
       "19  https://en.wikipedia.org/wiki/The_Dunwich_Horr...          1  \n",
       "20   https://en.wikipedia.org/wiki/Some_Voices_(film)          1  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = list(input().split())\n",
    "searchengine2(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "know light film star\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Intro</th>\n",
       "      <th>Url</th>\n",
       "      <th>Similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adventures of Captain Marvel</td>\n",
       "      <td>Adventures of Captain Marvel         ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Adventures_of_Ca...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Hour Before the Dawn</td>\n",
       "      <td>The Hour Before the Dawn             ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Hour_Before_...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Journey into Light</td>\n",
       "      <td>Journey into Light               is a...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Journey_into_Light</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adventures of Captain Marvel</td>\n",
       "      <td>Adventures of Captain Marvel         ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Adventures_of_Ca...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Hour Before the Dawn</td>\n",
       "      <td>The Hour Before the Dawn             ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Hour_Before_...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Journey into Light</td>\n",
       "      <td>Journey into Light               is a...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Journey_into_Light</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Adventures of Captain Marvel</td>\n",
       "      <td>Adventures of Captain Marvel         ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Adventures_of_Ca...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The Hour Before the Dawn</td>\n",
       "      <td>The Hour Before the Dawn             ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Hour_Before_...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Journey into Light</td>\n",
       "      <td>Journey into Light               is a...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Journey_into_Light</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Surviving the Game</td>\n",
       "      <td>Surviving the Game               is a...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Surviving_the_Game</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Fools Rush In (1997 film)</td>\n",
       "      <td>Fools Rush In               is a 1997...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Fools_Rush_In_(1...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Night of the Demons 3</td>\n",
       "      <td>Night of the Demons 3               (...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Night_of_the_Dem...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Stir of Echoes</td>\n",
       "      <td>Stir of Echoes               is a 199...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Stir_of_Echoes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Corky Romano</td>\n",
       "      <td>Corky Romano               is a 2001 ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Corky_Romano</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Stolen (2012 film)</td>\n",
       "      <td>Stolen               , formerly known...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Stolen_(2012_film)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>From Hell to Texas</td>\n",
       "      <td>From Hell to Texas               is a...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/From_Hell_to_Texas</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Silent Running</td>\n",
       "      <td>Silent Running               is a 197...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Silent_Running</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>A Dark Song</td>\n",
       "      <td>A Dark Song               is a 2016 I...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/A_Dark_Song</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Surviving the Game</td>\n",
       "      <td>Surviving the Game               is a...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Surviving_the_Game</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Fools Rush In (1997 film)</td>\n",
       "      <td>Fools Rush In               is a 1997...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Fools_Rush_In_(1...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Night of the Demons 3</td>\n",
       "      <td>Night of the Demons 3               (...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Night_of_the_Dem...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Title  \\\n",
       "0   Adventures of Captain Marvel   \n",
       "1       The Hour Before the Dawn   \n",
       "2             Journey into Light   \n",
       "3   Adventures of Captain Marvel   \n",
       "4       The Hour Before the Dawn   \n",
       "5             Journey into Light   \n",
       "6   Adventures of Captain Marvel   \n",
       "7       The Hour Before the Dawn   \n",
       "8             Journey into Light   \n",
       "9             Surviving the Game   \n",
       "10     Fools Rush In (1997 film)   \n",
       "11         Night of the Demons 3   \n",
       "12                Stir of Echoes   \n",
       "13                  Corky Romano   \n",
       "14            Stolen (2012 film)   \n",
       "15            From Hell to Texas   \n",
       "16                Silent Running   \n",
       "17                   A Dark Song   \n",
       "18            Surviving the Game   \n",
       "19     Fools Rush In (1997 film)   \n",
       "20         Night of the Demons 3   \n",
       "\n",
       "                                                Intro  \\\n",
       "0            Adventures of Captain Marvel         ...   \n",
       "1            The Hour Before the Dawn             ...   \n",
       "2            Journey into Light               is a...   \n",
       "3            Adventures of Captain Marvel         ...   \n",
       "4            The Hour Before the Dawn             ...   \n",
       "5            Journey into Light               is a...   \n",
       "6            Adventures of Captain Marvel         ...   \n",
       "7            The Hour Before the Dawn             ...   \n",
       "8            Journey into Light               is a...   \n",
       "9            Surviving the Game               is a...   \n",
       "10           Fools Rush In               is a 1997...   \n",
       "11           Night of the Demons 3               (...   \n",
       "12           Stir of Echoes               is a 199...   \n",
       "13           Corky Romano               is a 2001 ...   \n",
       "14           Stolen               , formerly known...   \n",
       "15           From Hell to Texas               is a...   \n",
       "16           Silent Running               is a 197...   \n",
       "17           A Dark Song               is a 2016 I...   \n",
       "18           Surviving the Game               is a...   \n",
       "19           Fools Rush In               is a 1997...   \n",
       "20           Night of the Demons 3               (...   \n",
       "\n",
       "                                                  Url Similarity  \n",
       "0   https://en.wikipedia.org/wiki/Adventures_of_Ca...          1  \n",
       "1   https://en.wikipedia.org/wiki/The_Hour_Before_...          1  \n",
       "2    https://en.wikipedia.org/wiki/Journey_into_Light          1  \n",
       "3   https://en.wikipedia.org/wiki/Adventures_of_Ca...          1  \n",
       "4   https://en.wikipedia.org/wiki/The_Hour_Before_...          1  \n",
       "5    https://en.wikipedia.org/wiki/Journey_into_Light          1  \n",
       "6   https://en.wikipedia.org/wiki/Adventures_of_Ca...          1  \n",
       "7   https://en.wikipedia.org/wiki/The_Hour_Before_...          1  \n",
       "8    https://en.wikipedia.org/wiki/Journey_into_Light          1  \n",
       "9    https://en.wikipedia.org/wiki/Surviving_the_Game          1  \n",
       "10  https://en.wikipedia.org/wiki/Fools_Rush_In_(1...          1  \n",
       "11  https://en.wikipedia.org/wiki/Night_of_the_Dem...          1  \n",
       "12       https://en.wikipedia.org/wiki/Stir_of_Echoes          1  \n",
       "13         https://en.wikipedia.org/wiki/Corky_Romano          1  \n",
       "14   https://en.wikipedia.org/wiki/Stolen_(2012_film)          1  \n",
       "15   https://en.wikipedia.org/wiki/From_Hell_to_Texas          1  \n",
       "16       https://en.wikipedia.org/wiki/Silent_Running          1  \n",
       "17          https://en.wikipedia.org/wiki/A_Dark_Song          1  \n",
       "18   https://en.wikipedia.org/wiki/Surviving_the_Game          1  \n",
       "19  https://en.wikipedia.org/wiki/Fools_Rush_In_(1...          1  \n",
       "20  https://en.wikipedia.org/wiki/Night_of_the_Dem...          1  "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = list(input().split())\n",
    "searchengine2(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disney movie 2019\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Intro</th>\n",
       "      <th>Url</th>\n",
       "      <th>Similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thumbelina (1994 film)</td>\n",
       "      <td>Thumbelina               (also known ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Thumbelina_(1994...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Avengers (2012 film)</td>\n",
       "      <td>Marvel's The Avengers                ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Avengers_(20...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cars 3</td>\n",
       "      <td>Cars 3               is a 2017 Americ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Cars_3</td>\n",
       "      <td>0.94335701356643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Frozen (2013 film)</td>\n",
       "      <td>Frozen               is a 2013 Americ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Frozen_(2013_film)</td>\n",
       "      <td>0.89654294215813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Chronicles of Narnia: Prince Caspian</td>\n",
       "      <td>The Chronicles of Narnia: Prince Casp...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Chronicles_o...</td>\n",
       "      <td>0.82684193281763</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Title  \\\n",
       "0                    Thumbelina (1994 film)   \n",
       "1                  The Avengers (2012 film)   \n",
       "2                                    Cars 3   \n",
       "3                        Frozen (2013 film)   \n",
       "4  The Chronicles of Narnia: Prince Caspian   \n",
       "\n",
       "                                               Intro  \\\n",
       "0           Thumbelina               (also known ...   \n",
       "1           Marvel's The Avengers                ...   \n",
       "2           Cars 3               is a 2017 Americ...   \n",
       "3           Frozen               is a 2013 Americ...   \n",
       "4           The Chronicles of Narnia: Prince Casp...   \n",
       "\n",
       "                                                 Url        Similarity  \n",
       "0  https://en.wikipedia.org/wiki/Thumbelina_(1994...                 1  \n",
       "1  https://en.wikipedia.org/wiki/The_Avengers_(20...                 1  \n",
       "2               https://en.wikipedia.org/wiki/Cars_3  0.94335701356643  \n",
       "3   https://en.wikipedia.org/wiki/Frozen_(2013_film)  0.89654294215813  \n",
       "4  https://en.wikipedia.org/wiki/The_Chronicles_o...  0.82684193281763  "
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = list(input().split())\n",
    "searchengine2(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "light light light film sun\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Intro</th>\n",
       "      <th>Url</th>\n",
       "      <th>Similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Multi-Facial</td>\n",
       "      <td>Multi-Facial               is a 1995 ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Multi-Facial</td>\n",
       "      <td>0.9999935714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Legend (1985 film)</td>\n",
       "      <td>Legend               is a 1985 Americ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Legend_(1985_film)</td>\n",
       "      <td>0.999985536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Blade II</td>\n",
       "      <td>Blade II               is a 2002 Amer...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Blade_II</td>\n",
       "      <td>0.9999598243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Close Encounters of the Third Kind</td>\n",
       "      <td>Close Encounters of the Third Kind   ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Close_Encounters...</td>\n",
       "      <td>0.9998698517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Little Monsters</td>\n",
       "      <td>Little Monsters               is a 19...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Little_Monsters</td>\n",
       "      <td>0.9980234564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Midnight Special (film)</td>\n",
       "      <td>Midnight Special               is a 2...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Midnight_Special...</td>\n",
       "      <td>0.9980109468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Pitch Black (film)</td>\n",
       "      <td>Pitch Black               (titled    ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Pitch_Black_(film)</td>\n",
       "      <td>0.9980109468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The Hallow</td>\n",
       "      <td>The Hallow               (originally ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Hallow</td>\n",
       "      <td>0.9948607933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>League of Gods</td>\n",
       "      <td>League of Gods               (       ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/League_of_Gods</td>\n",
       "      <td>0.9928853908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The Wraith</td>\n",
       "      <td>The Wraith               is a 1986   ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Wraith</td>\n",
       "      <td>0.9928681177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Home (2015 film)</td>\n",
       "      <td>Home               is a 2015 American...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Home_(2015_anima...</td>\n",
       "      <td>0.9927539708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Curious George (film)</td>\n",
       "      <td>Curious George               is a 200...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Curious_George_(...</td>\n",
       "      <td>0.9927539708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Pretty Woman</td>\n",
       "      <td>Pretty Woman               is a 1990 ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Pretty_Woman</td>\n",
       "      <td>0.9927088611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Hocus Pocus (1993 film)</td>\n",
       "      <td>Hocus Pocus               is a 1993 A...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Hocus_Pocus_(199...</td>\n",
       "      <td>0.9925987732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Megiddo: The Omega Code 2</td>\n",
       "      <td>Megiddo: The Omega Code 2            ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Megiddo:_The_Ome...</td>\n",
       "      <td>0.9918982343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>The Tree of Life (film)</td>\n",
       "      <td>The Tree of Life               is a 2...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Tree_of_Life...</td>\n",
       "      <td>0.9739265829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>A Far Off Place</td>\n",
       "      <td>A Far Off Place               (aka   ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/A_Far_Off_Place</td>\n",
       "      <td>0.9159937312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>I Love You, Beth Cooper (film)</td>\n",
       "      <td>I Love You, Beth Cooper              ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/I_Love_You,_Beth...</td>\n",
       "      <td>0.9159937312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Atlantis, the Lost Continent</td>\n",
       "      <td>Atlantis, the Lost Continent         ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Atlantis,_the_Lo...</td>\n",
       "      <td>0.9159937312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>I Love You, Beth Cooper (film)</td>\n",
       "      <td>I Love You, Beth Cooper              ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/I_Love_You,_Beth...</td>\n",
       "      <td>0.9159937312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Atlantis, the Lost Continent</td>\n",
       "      <td>Atlantis, the Lost Continent         ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Atlantis,_the_Lo...</td>\n",
       "      <td>0.9159937312</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Title  \\\n",
       "0                         Multi-Facial   \n",
       "1                   Legend (1985 film)   \n",
       "2                             Blade II   \n",
       "3   Close Encounters of the Third Kind   \n",
       "4                      Little Monsters   \n",
       "5              Midnight Special (film)   \n",
       "6                   Pitch Black (film)   \n",
       "7                           The Hallow   \n",
       "8                       League of Gods   \n",
       "9                           The Wraith   \n",
       "10                    Home (2015 film)   \n",
       "11               Curious George (film)   \n",
       "12                        Pretty Woman   \n",
       "13             Hocus Pocus (1993 film)   \n",
       "14           Megiddo: The Omega Code 2   \n",
       "15             The Tree of Life (film)   \n",
       "16                     A Far Off Place   \n",
       "17      I Love You, Beth Cooper (film)   \n",
       "18        Atlantis, the Lost Continent   \n",
       "19      I Love You, Beth Cooper (film)   \n",
       "20        Atlantis, the Lost Continent   \n",
       "\n",
       "                                                Intro  \\\n",
       "0            Multi-Facial               is a 1995 ...   \n",
       "1            Legend               is a 1985 Americ...   \n",
       "2            Blade II               is a 2002 Amer...   \n",
       "3            Close Encounters of the Third Kind   ...   \n",
       "4            Little Monsters               is a 19...   \n",
       "5            Midnight Special               is a 2...   \n",
       "6            Pitch Black               (titled    ...   \n",
       "7            The Hallow               (originally ...   \n",
       "8            League of Gods               (       ...   \n",
       "9            The Wraith               is a 1986   ...   \n",
       "10           Home               is a 2015 American...   \n",
       "11           Curious George               is a 200...   \n",
       "12           Pretty Woman               is a 1990 ...   \n",
       "13           Hocus Pocus               is a 1993 A...   \n",
       "14           Megiddo: The Omega Code 2            ...   \n",
       "15           The Tree of Life               is a 2...   \n",
       "16           A Far Off Place               (aka   ...   \n",
       "17           I Love You, Beth Cooper              ...   \n",
       "18           Atlantis, the Lost Continent         ...   \n",
       "19           I Love You, Beth Cooper              ...   \n",
       "20           Atlantis, the Lost Continent         ...   \n",
       "\n",
       "                                                  Url    Similarity  \n",
       "0          https://en.wikipedia.org/wiki/Multi-Facial  0.9999935714  \n",
       "1    https://en.wikipedia.org/wiki/Legend_(1985_film)   0.999985536  \n",
       "2              https://en.wikipedia.org/wiki/Blade_II  0.9999598243  \n",
       "3   https://en.wikipedia.org/wiki/Close_Encounters...  0.9998698517  \n",
       "4       https://en.wikipedia.org/wiki/Little_Monsters  0.9980234564  \n",
       "5   https://en.wikipedia.org/wiki/Midnight_Special...  0.9980109468  \n",
       "6    https://en.wikipedia.org/wiki/Pitch_Black_(film)  0.9980109468  \n",
       "7            https://en.wikipedia.org/wiki/The_Hallow  0.9948607933  \n",
       "8        https://en.wikipedia.org/wiki/League_of_Gods  0.9928853908  \n",
       "9            https://en.wikipedia.org/wiki/The_Wraith  0.9928681177  \n",
       "10  https://en.wikipedia.org/wiki/Home_(2015_anima...  0.9927539708  \n",
       "11  https://en.wikipedia.org/wiki/Curious_George_(...  0.9927539708  \n",
       "12         https://en.wikipedia.org/wiki/Pretty_Woman  0.9927088611  \n",
       "13  https://en.wikipedia.org/wiki/Hocus_Pocus_(199...  0.9925987732  \n",
       "14  https://en.wikipedia.org/wiki/Megiddo:_The_Ome...  0.9918982343  \n",
       "15  https://en.wikipedia.org/wiki/The_Tree_of_Life...  0.9739265829  \n",
       "16      https://en.wikipedia.org/wiki/A_Far_Off_Place  0.9159937312  \n",
       "17  https://en.wikipedia.org/wiki/I_Love_You,_Beth...  0.9159937312  \n",
       "18  https://en.wikipedia.org/wiki/Atlantis,_the_Lo...  0.9159937312  \n",
       "19  https://en.wikipedia.org/wiki/I_Love_You,_Beth...  0.9159937312  \n",
       "20  https://en.wikipedia.org/wiki/Atlantis,_the_Lo...  0.9159937312  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = list(input().split())\n",
    "searchengine2(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ex[3] build a new engine with a personal Score!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The engine will take the best 20 of engine2 and perform a score on everyone of therm, about: \n",
    "<br>\n",
    "    1) the string we gave has one or more words in the title (1 word=1 point)\n",
    "    <br>\n",
    "    2) the string we gave has 2 or more words in the starring section (2 words = 1 point)\n",
    "    <br>\n",
    "    3) the film has 4 or more 'na' > -1 point\n",
    "    4) the length of intro+plot is above the average of len(intro+plot) > +1 point\n",
    "    <br>\n",
    "    5) the length of intro+plot is below the average of len(intro+plot) > -1 point\n",
    "    <br>\n",
    "    6) in the string the words given match(beetween intro-plot-starring-director) more than 3 times > +1 point every word that matches at least 3 times.\n",
    "    <br>\n",
    "    7) in the string every word matches (beetween intro-plot-starring-director) more than 2 times > +1 point\n",
    "    <br>\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lone ladi'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "titles = {}\n",
    "for i in range(50):\n",
    "    file = \"Cleantsv/filmclean-\"+str(i)+'.tsv'\n",
    "    datatemp = pd.read_csv(file, delimiter = '\\t')\n",
    "    title =  datatemp['title'][0]\n",
    "    titles[file]=title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eddi cruiser\n",
      "eddi cruiser 1983 american film direct martin davidson screenplay written director arlen davidson base novel p f kluge sequel eddi cruiser ii eddi live follow 1989\n",
      "televis report name maggi foley investig mysteri disappear legendari rock star eddi wilson flashback dramat eddi life rise fall rock roll band eddi cruiser band get start somer point new jersey club call toni mart adept write lyric eddi hire frank ridgeway aka wordman band keyboard player lyricist protest band manag doc robbin bassist sal amato round cruiser saxophonist wendel newton background singer eddi girlfriend joann carlino drummer kenni hopkin band first album tender year becam major hit record next album season hell turn nightmar inspir bleak fatalist poetri arthur rimbaud eddi push bandmat beyond limit music person eddi want great bassist sal repli great guy jersey eddi make clear band cannot great reason ever play music season hell ultim reject satin record ground dark strang earli morn hour eddi car crash rail stainton memori causeway eddi vanish without trace bodi never found almost 18 year later satin releas band first album chart even higher origin televis documentari soon work explor mysteri band second album disappear vault satin record day eddi disappear origin cruiser set particip except eddi wendel newton die overdos report heart attack august 1963 age 37 other live ordinari live sal amato front cruiser tribut band ridgeway high school english teacher vineland doc work radio disc jockey asburi park joann stage choreograph wildwood hopkin work atlant citi casino documentari interview band express desir reliv past even though mani memori humili exampl concert benton colleg frank student eddi ridicul frank repeatedli refer tobi tyler see joann kiss concert cruiser member share similar stori joann abl complet one piec puzzl frank could reveal happen band second album storm studio eddi brought palac depress makeshift castl made garbag junk visit often child reveal fact took master tape album satin record hide palac depress felt belong frank joann go back palac depress retriev master tape mysteri man drive blue 57 chevi bel air convert ident eddi arriv hous call joann reach car frank unmask impostor reveal doc master tape year move stori frank joann give master tape doc drive night vow cruiser final conquer world time joann invit frank hous surpris reveal end beard much older look eddi shown aliv watch multipl televis window applianc store end credit foley documentari tribut band roll smile seren proud know work final heard disappear night\n",
      "eddi cruiser\n",
      "martin davidson\n",
      "joseph brook robert k lifton\n",
      "na\n",
      "tom bereng michael paré\n",
      "john cafferti\n",
      "septemb 23 1983 1983 09 23\n",
      "95 minut\n",
      "unit state\n",
      "english\n",
      "5 million 1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "titles = {}\n",
    "for i in range(30):\n",
    "    file = \"Cleantsv/filmclean-\"+str(i)+'.tsv'\n",
    "    datatemp = pd.read_csv(file, delimiter = '\\t')\n",
    "#datatemp['intro'][0]+datatemp['plot'][0]\n",
    "for i in datatemp.values[0]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "Docum_and_words = []\n",
    "for i in range(30000):\n",
    "    file = \"Cleantsv/filmclean-\"+str(i)+'.tsv'\n",
    "    file1 = open(file, encoding=\"utf8\") \n",
    "    line = file1.read()\n",
    "    words = line.split('\\t') \n",
    "    wordssplitted1 = words[14].split()\n",
    "    wordssplitted2 = words[15].split()\n",
    "    words = wordssplitted1+wordssplitted2\n",
    "    A = \" \".join(words)\n",
    "    Docum_and_words.append(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(Docum_and_words[0].split())\n",
    "total = 0\n",
    "for i in Docum_and_words:\n",
    "    total = total + len(i.split())\n",
    "average = float(total)/30000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "266.1692"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "def score_function(doc, lizt, z, x):\n",
    "    average = 266\n",
    "    score = 0\n",
    "    half = 0\n",
    "    da = pd.read_csv(doc, delimiter = '\\t')\n",
    "    for i in range(len(lizt)):\n",
    "        if lizt[i] in da['title'][0].split() and x == 'no':\n",
    "            score = score + 1\n",
    "        if lizt[i] in da['starring'][0].split():\n",
    "            half = half + 1\n",
    "    if z == da['language'][0]:\n",
    "        score = score + 4\n",
    "    if x == 'yes':\n",
    "        score = score + half*7\n",
    "    intro_plot = da['plot'][0]+da['intro'][0]\n",
    "    value = len(intro_plot.split())\n",
    "    if value > average:\n",
    "        score = score + 4\n",
    "    if value < (average-50):\n",
    "        score = score -6\n",
    "    na = 0\n",
    "    for i in da.values[0]:\n",
    "        if i == 'na':\n",
    "            na = na +1\n",
    "    if na > 3:\n",
    "        score = score - 4\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Engine3!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome in search engine3, write a string and, after some more questions I will give you a very likely film you can be looking for!daniel craig \n",
      "Write your preferred languageenglish\n",
      "You gave an actor/actress name in the string? type yes or noyes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Intro</th>\n",
       "      <th>Url</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Turner &amp; Hooch</td>\n",
       "      <td>Turner &amp; Hooch               is a 198...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Turner_%26_Hooch</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Power of One (film)</td>\n",
       "      <td>The Power of One               is a 1...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Power_of_One...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101 Dalmatians (1996 film)</td>\n",
       "      <td>101 Dalmatians               is a 199...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/101_Dalmatians_(...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Twisted Desire</td>\n",
       "      <td>Twisted Desire               is a 199...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Twisted_Desire</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Thirteenth Floor</td>\n",
       "      <td>The Thirteenth Floor               is...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Thirteenth_F...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lara Croft: Tomb Raider</td>\n",
       "      <td>Lara Croft: Tomb Raider              ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Lara_Croft:_Tomb...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Road to Perdition</td>\n",
       "      <td>Road to Perdition               is a ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Road_to_Perdition</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Casino Royale (2006 film)</td>\n",
       "      <td>Casino Royale               is a 2006...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Casino_Royale_(2...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Infamous (film)</td>\n",
       "      <td>Infamous               is a 2006 Amer...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Infamous_(film)</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The Golden Compass (film)</td>\n",
       "      <td>The Golden Compass               is a...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Golden_Compa...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Defiance (2008 film)</td>\n",
       "      <td>Defiance               is a 2008 Amer...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Defiance_(2008_f...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Quantum of Solace</td>\n",
       "      <td>Quantum of Solace               is a ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Quantum_of_Solace</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>The Adventures of Tintin (film)</td>\n",
       "      <td>The Adventures of Tintin             ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Adventures_o...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Cowboys &amp; Aliens</td>\n",
       "      <td>Cowboys &amp; Aliens               is a 2...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Cowboys_%26_Aliens</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Dream House (2011 film)</td>\n",
       "      <td>Dream House               is a 2011 A...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Dream_House_(201...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>The Girl with the Dragon Tattoo (2011 film)</td>\n",
       "      <td>The Girl with the Dragon Tattoo      ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Girl_with_th...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Identity Thief</td>\n",
       "      <td>Identity Thief               is a 201...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Identity_Thief</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Snitch (film)</td>\n",
       "      <td>Snitch               is a 2013 Americ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Snitch_(film)</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>The Longest Ride (film)</td>\n",
       "      <td>The Longest Ride               is a 2...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Longest_Ride...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Title  \\\n",
       "0                                Turner & Hooch   \n",
       "1                       The Power of One (film)   \n",
       "2                    101 Dalmatians (1996 film)   \n",
       "3                                Twisted Desire   \n",
       "4                          The Thirteenth Floor   \n",
       "5                       Lara Croft: Tomb Raider   \n",
       "6                             Road to Perdition   \n",
       "7                     Casino Royale (2006 film)   \n",
       "8                               Infamous (film)   \n",
       "9                     The Golden Compass (film)   \n",
       "10                         Defiance (2008 film)   \n",
       "11                            Quantum of Solace   \n",
       "12              The Adventures of Tintin (film)   \n",
       "13                             Cowboys & Aliens   \n",
       "14                      Dream House (2011 film)   \n",
       "15  The Girl with the Dragon Tattoo (2011 film)   \n",
       "16                               Identity Thief   \n",
       "17                                Snitch (film)   \n",
       "18                      The Longest Ride (film)   \n",
       "\n",
       "                                                Intro  \\\n",
       "0            Turner & Hooch               is a 198...   \n",
       "1            The Power of One               is a 1...   \n",
       "2            101 Dalmatians               is a 199...   \n",
       "3            Twisted Desire               is a 199...   \n",
       "4            The Thirteenth Floor               is...   \n",
       "5            Lara Croft: Tomb Raider              ...   \n",
       "6            Road to Perdition               is a ...   \n",
       "7            Casino Royale               is a 2006...   \n",
       "8            Infamous               is a 2006 Amer...   \n",
       "9            The Golden Compass               is a...   \n",
       "10           Defiance               is a 2008 Amer...   \n",
       "11           Quantum of Solace               is a ...   \n",
       "12           The Adventures of Tintin             ...   \n",
       "13           Cowboys & Aliens               is a 2...   \n",
       "14           Dream House               is a 2011 A...   \n",
       "15           The Girl with the Dragon Tattoo      ...   \n",
       "16           Identity Thief               is a 201...   \n",
       "17           Snitch               is a 2013 Americ...   \n",
       "18           The Longest Ride               is a 2...   \n",
       "\n",
       "                                                  Url Score  \n",
       "0      https://en.wikipedia.org/wiki/Turner_%26_Hooch     8  \n",
       "1   https://en.wikipedia.org/wiki/The_Power_of_One...     8  \n",
       "2   https://en.wikipedia.org/wiki/101_Dalmatians_(...     8  \n",
       "3        https://en.wikipedia.org/wiki/Twisted_Desire     8  \n",
       "4   https://en.wikipedia.org/wiki/The_Thirteenth_F...     8  \n",
       "5   https://en.wikipedia.org/wiki/Lara_Croft:_Tomb...     8  \n",
       "6     https://en.wikipedia.org/wiki/Road_to_Perdition     8  \n",
       "7   https://en.wikipedia.org/wiki/Casino_Royale_(2...     8  \n",
       "8       https://en.wikipedia.org/wiki/Infamous_(film)     8  \n",
       "9   https://en.wikipedia.org/wiki/The_Golden_Compa...     8  \n",
       "10  https://en.wikipedia.org/wiki/Defiance_(2008_f...     8  \n",
       "11    https://en.wikipedia.org/wiki/Quantum_of_Solace     8  \n",
       "12  https://en.wikipedia.org/wiki/The_Adventures_o...     8  \n",
       "13   https://en.wikipedia.org/wiki/Cowboys_%26_Aliens     8  \n",
       "14  https://en.wikipedia.org/wiki/Dream_House_(201...     8  \n",
       "15  https://en.wikipedia.org/wiki/The_Girl_with_th...     8  \n",
       "16       https://en.wikipedia.org/wiki/Identity_Thief     8  \n",
       "17        https://en.wikipedia.org/wiki/Snitch_(film)     8  \n",
       "18  https://en.wikipedia.org/wiki/The_Longest_Ride...     8  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#HERE i DEFINE THE FUNCTION TO RECEIVE THE DATASET, GIVEN AN INPUT\n",
    "import heapq as hq\n",
    "def tf(word, doc):\n",
    "    return doc.count(word) / len(doc)\n",
    "y = list(input('Welcome in search engine3, write a string and, after some more questions I will give you a very likely film you can be looking for!').split())\n",
    "z = input('Write your preferred language')\n",
    "x = input('You gave an actor/actress name in the string? type yes or no')\n",
    "def searchengine3(y, z, x):\n",
    "    for i in range(len(y)):\n",
    "        y[i]= preprocess(str(y[i]))\n",
    "    #Now I tranform the list of input in a list of the codes in the dictiionary based on the input\n",
    "    yfinal=[] #use this because some words have no match in the vocabulary\n",
    "    for i in range(len(y)):\n",
    "        #print(y[i])\n",
    "        if y[i] in diction:\n",
    "            yfinal.append(diction[y[i]])\n",
    "    #Now I have to search inside the lists of values from the keys i foundb and see if some films match in the various keys.\n",
    "    if  len(yfinal)<len(y):\n",
    "        return print('We are sorry there are no films, in my database, that match ALL the words you gave me !(')\n",
    "    else:\n",
    "        starting_values = diction2[yfinal[0]]\n",
    "        final_values = starting_values.copy()\n",
    "        for codes in range(1,len(yfinal)):\n",
    "            new = []\n",
    "            for film in final_values:\n",
    "                if film in diction2[yfinal[codes]]:\n",
    "                    new.append(film)\n",
    "            final_values = new\n",
    "        megaDataframe = pd.DataFrame(columns = ['Title', 'Intro', 'Url', 'Score'])\n",
    "        if not final_values:\n",
    "            return print(\"Wow no film matched my quiery, I need more films to compare!\")\n",
    "        else:  \n",
    "            dict_score = {}\n",
    "            score_list = []\n",
    "            Threshold  = 2\n",
    "            k_limit = 19\n",
    "            #print(final_values)\n",
    "            for doc in final_values:\n",
    "                #score_function is the function I create and used to give points to every film\n",
    "                x = preprocess(x)\n",
    "                z = preprocess(z)\n",
    "                score = score_function(doc, y, z, x)\n",
    "                if score not in dict_score:\n",
    "                    dict_score[score]=[doc]\n",
    "                    score_list.append(score)\n",
    "                else:\n",
    "                    dict_score[score].append(doc)\n",
    "            score_list = list(set(score_list))\n",
    "            best = hq.nlargest(Threshold, score_list)\n",
    "            k = 0\n",
    "            for score in best:\n",
    "                if k < k_limit :\n",
    "                    for document in dict_score[score]:\n",
    "                        if k < k_limit:\n",
    "                            totakeurl = document.replace('Cleantsv/filmclean-','')\n",
    "                            totakeurl = str(int(totakeurl.replace('.tsv', '')))\n",
    "                            url = dicturls[totakeurl]\n",
    "                            Score = score\n",
    "                            temporary = pd.read_csv('Tsvfiles/'+'film'+(totakeurl)+'.tsv',delimiter='\\t' )\n",
    "                            title = temporary['title'][0]\n",
    "                            intro =  temporary['intro'][0].replace('\\r\\n','')\n",
    "                            new_row = [title, intro, url, Score]\n",
    "                            megaDataframe.loc[k]=new_row \n",
    "                            k = k+1\n",
    "                        else:\n",
    "                            return megaDataframe\n",
    "                else:\n",
    "                    return megaDataframe\n",
    "                \n",
    "            \n",
    "A = searchengine3(y, z, x)\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome in search engine3, write a string and, after some more questions I will give you a very likely film you can be looking for!james bond\n",
      "Write your preferred languageenglish\n",
      "You gave an actor/actress name in the string? type yes or nono\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Intro</th>\n",
       "      <th>Url</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Coming to America</td>\n",
       "      <td>Coming to America               is a ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Coming_to_America</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Soul Food (film)</td>\n",
       "      <td>Soul Food               is a 1997 Ame...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Soul_Food_(film)</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ninja Assassin</td>\n",
       "      <td>Ninja Assassin               is a 200...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Ninja_Assassin</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kung Fu Panda 3</td>\n",
       "      <td>Kung Fu Panda 3               is a 20...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Kung_Fu_Panda_3</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Deepwater Horizon (film)</td>\n",
       "      <td>Deepwater Horizon               is a ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Deepwater_Horizo...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Title  \\\n",
       "0         Coming to America   \n",
       "1          Soul Food (film)   \n",
       "2            Ninja Assassin   \n",
       "3           Kung Fu Panda 3   \n",
       "4  Deepwater Horizon (film)   \n",
       "\n",
       "                                               Intro  \\\n",
       "0           Coming to America               is a ...   \n",
       "1           Soul Food               is a 1997 Ame...   \n",
       "2           Ninja Assassin               is a 200...   \n",
       "3           Kung Fu Panda 3               is a 20...   \n",
       "4           Deepwater Horizon               is a ...   \n",
       "\n",
       "                                                 Url Score  \n",
       "0    https://en.wikipedia.org/wiki/Coming_to_America     8  \n",
       "1     https://en.wikipedia.org/wiki/Soul_Food_(film)     8  \n",
       "2       https://en.wikipedia.org/wiki/Ninja_Assassin     8  \n",
       "3      https://en.wikipedia.org/wiki/Kung_Fu_Panda_3     8  \n",
       "4  https://en.wikipedia.org/wiki/Deepwater_Horizo...     8  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = list(input('Welcome in search engine3, write a string and, after some more questions I will give you a very likely film you can be looking for!').split())\n",
    "z = input('Write your preferred language')\n",
    "x = input('You gave an actor/actress name in the string? type yes or no')\n",
    "searchengine3(y, z, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome in search engine3, write a string and, after some more questions I will give you a very likely film you can be looking for!casino royale\n",
      "Write your preferred languageenaglish\n",
      "You gave an actor/actress name in the string? type yes or nono\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Intro</th>\n",
       "      <th>Url</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Casino Royale (2006 film)</td>\n",
       "      <td>Casino Royale               is a 2006...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Casino_Royale_(2...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Casino Royale (1967 film)</td>\n",
       "      <td>Casino Royale               is a 1967...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Casino_Royale_(1...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Quantum of Solace</td>\n",
       "      <td>Quantum of Solace               is a ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Quantum_of_Solace</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Thunderball (film)</td>\n",
       "      <td>Thunderball               is a 1965 B...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Thunderball_(film)</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Khartoum (film)</td>\n",
       "      <td>Khartoum               is a 1966 film...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Khartoum_(film)</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Title  \\\n",
       "0  Casino Royale (2006 film)   \n",
       "1  Casino Royale (1967 film)   \n",
       "2          Quantum of Solace   \n",
       "3         Thunderball (film)   \n",
       "4            Khartoum (film)   \n",
       "\n",
       "                                               Intro  \\\n",
       "0           Casino Royale               is a 2006...   \n",
       "1           Casino Royale               is a 1967...   \n",
       "2           Quantum of Solace               is a ...   \n",
       "3           Thunderball               is a 1965 B...   \n",
       "4           Khartoum               is a 1966 film...   \n",
       "\n",
       "                                                 Url Score  \n",
       "0  https://en.wikipedia.org/wiki/Casino_Royale_(2...     6  \n",
       "1  https://en.wikipedia.org/wiki/Casino_Royale_(1...     6  \n",
       "2    https://en.wikipedia.org/wiki/Quantum_of_Solace     4  \n",
       "3   https://en.wikipedia.org/wiki/Thunderball_(film)     4  \n",
       "4      https://en.wikipedia.org/wiki/Khartoum_(film)     4  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = list(input('Welcome in search engine3, write a string and, after some more questions I will give you a very likely film you can be looking for!').split())\n",
    "z = input('Write your preferred language')\n",
    "x = input('You gave an actor/actress name in the string? type yes or no')\n",
    "searchengine3(y, z, x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
