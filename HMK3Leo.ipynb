{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [1.1] Get the list of movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(open('C:/Users/leona/Desktop/ADMHMK-3/movies1.html'), \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<style>\n",
       " table, th, td {border: 1px solid black;}</style>,\n",
       " <link href=\"https://www.w3schools.com/browserref.css\" rel=\"stylesheet\" type=\"text/css\"/>]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_a = soup.select('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lst_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = []\n",
    "for i in lst_a:\n",
    "    urls.append(i.get('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now I have a list with all the urls, so let's start the next point!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [1.2] Crawl Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.error import URLError, HTTPError, ContentTooShortError\n",
    "import time\n",
    "k=0\n",
    "for i in range(len(urls)):\n",
    "    try:\n",
    "        ur_l = requests.get(urls[i])\n",
    "        soup = BeautifulSoup(ur_l.content, 'html.parser')\n",
    "        soup = soup.prettify(\"utf-8\")        \n",
    "        stringa = 'Articles/article-'+str(k)+'.html'\n",
    "        k = k+1\n",
    "        Html_file= open(stringa, \"wb\")\n",
    "        Html_file.write(soup)\n",
    "        Html_file.close()\n",
    "    except(URLError,HTTPError, ContentTooShortError)  as e:\n",
    "        html = None\n",
    "    time.sleep(1)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [1.3] Parse downloaded pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "myfile = open(\"Articles/article-0.html\")\n",
    "#soup = BeautifulSoup(myfile, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import io\n",
    "for i in range(1):\n",
    "    filename = \"Articles/article-\"+str(i)+\".html\"\n",
    "    with open(filename, encoding=\"utf-8\") as f:\n",
    "        data = f.read()\n",
    "        soup = BeautifulSoup(data, 'html.parser')\n",
    "        #Now That I opened the file I have to look for the section asked\n",
    "        titlepage = soup.title.string\n",
    "        titleonly = titlepage.split(\"- Wikipedia\")\n",
    "        titlepage = titleonly[0].strip()\n",
    "        intro = ''\n",
    "        plot = ''\n",
    "        start = soup.find('p')\n",
    "        intro = start\n",
    "        intro1 = start.text\n",
    "        #print('EILa')\n",
    "        B = ''\n",
    "        B = intro.find_next_sibling('h2')\n",
    "        if(B!=None and B.find_next_sibling('p')):\n",
    "            C = B.find_next_sibling('p')\n",
    "            #print(intro1)\n",
    "            #print(intro.find_next_sibling('p'))\n",
    "            #print(B)\n",
    "            while(C != intro.find_next_sibling('p')): \n",
    "                intro1 = intro1 + intro.find_next_sibling('p').text\n",
    "                intro = intro.find_next_sibling('p')\n",
    "            plot = ''            \n",
    "            plot = B\n",
    "        #print(intro)\n",
    "            plot1 = ''\n",
    "            compare = ''\n",
    "            if(B.find_next_sibling('h2')):\n",
    "                compare = B.find_next_sibling('h2')\n",
    "                compareto = compare.find_next_sibling('p')\n",
    "                #plot1 = B.find_next_sibling('p').text\n",
    "                #print(compareto)\n",
    "                #print(plot1)\n",
    "                while(compareto != plot.find_next_sibling('p')):\n",
    "                    plot1 = plot1 + plot.find_next_sibling('p').text\n",
    "                    #print(plot1)\n",
    "                    plot = plot.find_next_sibling('p')\n",
    "        if(intro1 == ''):\n",
    "            intro1 = \"NA\"\n",
    "        if plot1 == '':\n",
    "            plot1 = \"NA\"\n",
    "        intro = intro1\n",
    "        plot = plot1\n",
    "        film_name = 'NA'\n",
    "        director = \"NA\"\n",
    "        producer = \"NA\"\n",
    "        writer = \"NA\"\n",
    "        starring = \"NA\"\n",
    "        music = \"NA\"\n",
    "        release_date = \"NA\"\n",
    "        runtime = \"NA\"\n",
    "        country = \"NA\"\n",
    "        language = \"NA\"\n",
    "        budget = \"NA\"\n",
    "#'film_name', 'director', 'producer','writer', 'starring', 'music', 'release date', 'runtime', 'country', 'language', 'budget'\n",
    "        for link in soup.find_all('tr'):\n",
    "            if soup.find('th',{'class': ['summary']})!= None:\n",
    "                    film_name = soup.find('th',{'class': ['summary']} ).text.strip()\n",
    "            if link.th:\n",
    "                if(link.th.text.strip() == 'Directed by'):\n",
    "                     director = link.td.text.strip()\n",
    "                elif(link.th.text.strip() == 'Produced by'):\n",
    "                      producer = link.td.text.strip()\n",
    "                elif(link.th.text.strip() == 'Written by'):\n",
    "                    writer = link.td.text.strip()\n",
    "                elif(link.th.text.strip() == 'Starring'):\n",
    "                    starring = link.td.text.strip()\n",
    "                elif(link.th.text.strip() == 'Music by'):\n",
    "                     music = link.td.text.strip()               \n",
    "                elif(link.th.text.strip() == 'Release date'):\n",
    "                    release_date = link.td.text.strip()\n",
    "                elif(link.th.text.strip() == 'Running time'):\n",
    "                    runtime = link.td.text.strip()\n",
    "                elif(link.th.text.strip() == 'Country'):\n",
    "                    if link.td:\n",
    "                        country = link.td.text.strip()\n",
    "                elif(link.th.text.strip() == 'Language'):\n",
    "                    language = link.td.text.strip()\n",
    "                elif(link.th.text.strip() == 'Budget'):\n",
    "                    budget = link.td.text.strip()\n",
    "        \n",
    "        tsvname = 'Tsvfiles/'+'film'+str(i)\n",
    "        with io.open(tsvname, \"w\", encoding=\"utf-8\") as out_file:\n",
    "        #with open(tsvname, 'w') as out_file:\n",
    "            tsv_writer = csv.writer(out_file, delimiter='\\t')\n",
    "            tsv_writer.writerow(['title','intro', 'plot', 'film_name', 'director', 'producer','writer', 'starring', 'music', 'release date', 'runtime', 'country', 'language', 'budget'])\n",
    "            tsv_writer.writerow([titlepage, intro, plot, film_name, director, producer, writer, starring, music, release_date, runtime, \n",
    "                 country, language, budget])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Love by the Light of the Moon'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titlepage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n\\n         Love by the Light of the Moon\\n        \\n\\n       is a 1901 film by\\n       \\n        Edwin S. Porter\\n       \\n       , produced by the\\n       \\n        Edison Manufacturing Company\\n       \\n       .\\n       \\n\\n         [1]\\n        \\n\\n       It mixes animation and live action and predates the\\n       \\n        man in the moon\\n       \\n       theme of the 1902 French science fiction film\\n       \\n\\n         A Trip to the Moon\\n        \\n\\n       by\\n       \\n        Georges Méliès\\n       \\n       .\\n      '"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "         Should a Woman Divorce?\n",
      "        \n",
      "\n",
      "       is a\n",
      "       \n",
      "        1914\n",
      "       \n",
      "\n",
      "        silent film\n",
      "       \n",
      "       written by\n",
      "       \n",
      "        Ivan Abramson\n",
      "       \n",
      "       and directed by\n",
      "       \n",
      "        Edwin McKim\n",
      "       \n",
      "       , and starring Lea Leland and Leonid Samoloff.\n",
      "      \n",
      "POI PLOT\n",
      "\n",
      "       Grace Roberts (played by Lea Leland), marries rancher Edward Smith, who is revealed to be a neglectful, vice-ridden spouse.  They have a daughter, Vivian.  Dr. Franklin (Leonid Samoloff) whisks Grace away from this unhappy life, and they move to New York under aliases, pretending to be married (since surely Smith would not agree to a divorce).  Grace and Franklin have a son, Walter (\n",
      "       \n",
      "        Milton S. Gould\n",
      "       \n",
      "       ).  Vivian gets sick, however, and Grace and Franklin return to save her.   Somehow this reunion, as Smith had assumed Grace to be dead, causes the death of Franklin.   This plot device frees Grace to return to her father's farm with both children.\n",
      "       \n",
      "\n",
      "         [1]\n",
      "        \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "intro = ''\n",
    "plot = ''\n",
    "start = soup.find('p')\n",
    "intro = start\n",
    "intro1 = start.text\n",
    "#print('EILa')\n",
    "B = ''\n",
    "B = intro.find_next_sibling('h2')\n",
    "C = B.find_next_sibling('p')\n",
    "#print(intro1)\n",
    "#print(intro.find_next_sibling('p'))\n",
    "#print(B)\n",
    "while(C != intro.find_next_sibling('p')): \n",
    "            intro1= intro1 + intro.find_next_sibling('p').text\n",
    "            intro = intro.find_next_sibling('p')\n",
    "plot = ''            \n",
    "plot = B\n",
    "#print(intro)\n",
    "plot1 = ''\n",
    "compare = ''\n",
    "compare = B.find_next_sibling('h2')\n",
    "compareto = compare.find_next_sibling('p')\n",
    "#plot1 = B.find_next_sibling('p').text\n",
    "#print(compareto)\n",
    "#print(plot1)\n",
    "while(compareto != plot.find_next_sibling('p')):\n",
    "        plot1 = plot1 + plot.find_next_sibling('p').text\n",
    "        #print(plot1)\n",
    "        plot = plot.find_next_sibling('p')\n",
    "        #print(plot)\n",
    "print(intro1)\n",
    "print(\"POI PLOT\")\n",
    "print(plot1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\leona\\anaconda3\\lib\\site-packages (3.4.5)\n",
      "Requirement already satisfied: six in c:\\users\\leona\\anaconda3\\lib\\site-packages (from nltk) (1.12.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>intro</th>\n",
       "      <th>plot</th>\n",
       "      <th>film_name</th>\n",
       "      <th>director</th>\n",
       "      <th>producer</th>\n",
       "      <th>writer</th>\n",
       "      <th>starring</th>\n",
       "      <th>music</th>\n",
       "      <th>release date</th>\n",
       "      <th>runtime</th>\n",
       "      <th>country</th>\n",
       "      <th>language</th>\n",
       "      <th>budget</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>budget arcadian maid</td>\n",
       "      <td>arcadian maid 1910 american silent film direct...</td>\n",
       "      <td>mari pickford play priscilla unemploy maid fin...</td>\n",
       "      <td>arcadian maid</td>\n",
       "      <td>w griffith</td>\n",
       "      <td>biograph compani</td>\n",
       "      <td>stanner e v taylor writer</td>\n",
       "      <td>mari pickford</td>\n",
       "      <td>na</td>\n",
       "      <td>august 1 1910 1910 08 01</td>\n",
       "      <td>16 minut 16 frame</td>\n",
       "      <td>unit state</td>\n",
       "      <td>silent english titl</td>\n",
       "      <td>na</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  title                                              intro  \\\n",
       "0  budget arcadian maid  arcadian maid 1910 american silent film direct...   \n",
       "\n",
       "                                                plot      film_name  \\\n",
       "0  mari pickford play priscilla unemploy maid fin...  arcadian maid   \n",
       "\n",
       "     director          producer                     writer       starring  \\\n",
       "0  w griffith  biograph compani  stanner e v taylor writer  mari pickford   \n",
       "\n",
       "  music              release date            runtime     country  \\\n",
       "0    na  august 1 1910 1910 08 01  16 minut 16 frame  unit state   \n",
       "\n",
       "              language budget  \n",
       "0  silent english titl     na  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dataset1 = pd.read_csv('Cleanfile/filmclean-25.tsv', delimiter='\\t')\n",
    "#dataset1 = pd.read_csv('Tsvfiles/film1', delimiter='\\t')\n",
    "dataset1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import io \n",
    "import nltk\n",
    "import csv\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    "#word_tokenize accepts a string as an input, not a file. \n",
    "stop_words = set(stopwords.words('english')) \n",
    "from nltk.stem import PorterStemmer \n",
    "#from nltk.tokenize import word_tokenize \n",
    "   \n",
    "ps = PorterStemmer() \n",
    "def preprocess(sentence):\n",
    "    #ps = PorterStemmer()\n",
    "    sentence = sentence.lower()\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokens = tokenizer.tokenize(sentence)\n",
    "    filtered_words = [ps.stem(w) for w in tokens if not w in stopwords.words('english')]\n",
    "    return \" \".join(filtered_words)\n",
    "for i in range(30):\n",
    "    file1 = open('Tsvfiles/film'+str(i), encoding=\"utf8\") \n",
    "    line = file1.read()# Use this to read file content as a stream: \n",
    "    #print(line)\n",
    "    words = line.split('\\t') \n",
    "    #print(words)\n",
    "    for j in range(13, len(words)):\n",
    "        words[j] = preprocess(words[j])\n",
    "        #print(words[j])\n",
    "        #word = word.split()\n",
    "        #for r in word:\n",
    "           # if r in stop_words:\n",
    "                #word.remove(r)\n",
    "                #print(r)\n",
    "            \n",
    "    #print(words)    \n",
    "    tsvname = \"Cleanfile/filmclean-\"+str(i)+'.tsv'\n",
    "    with io.open(tsvname, \"w\", encoding=\"utf-8\") as out_file:\n",
    "        #with open(tsvname, 'w') as out_file:\n",
    "            tsv_writer = csv.writer(out_file, delimiter='\\t')\n",
    "            tsv_writer.writerow(['title','intro', 'plot', 'film_name', 'director', 'producer','writer', 'starring', 'music', 'release date', 'runtime', 'country', 'language', 'budget'])\n",
    "            tsv_writer.writerow(words[13:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"\\n\\n\\n\\n         Alice in Wonderland\\n        \\n\\n       is a 1903 British\\n       \\n        silent film\\n       \\n       directed by\\n       \\n        Cecil Hepworth\\n       \\n       and\\n       \\n        Percy Stow\\n       \\n       .\\n       \\n\\n         [1]\\n        \\n\\n       Only one copy of the original film is known to exist. The\\n       \\n        British Film Institute\\n       \\n       (BFI) partially restored the movie and its original\\n       \\n        film tinting\\n       \\n       and released it in 2010. According to BFI, the original film ran about 12 minutes; the restoration runs 9 minutes and 35 seconds.\\n       \\n\\n         [1]\\n        \\n\\n       At the beginning of the restoration, it states that this is the first movie adaptation of\\n       \\n        Lewis Carroll\\n       \\n       \\'s children\\'s book\\n       \\n\\n         Alice\\'s Adventures in Wonderland\\n        \\n\\n       .\\n       \\n\\n         [2]\\n        \\n\\n\\n       The film is memorable for its use of\\n       \\n        special effects\\n       \\n       , including Alice\\'s shrinking in the Hall of Many Doors, and in her large size, stuck inside of White Rabbit\\'s home, reaching for help through a window.\\n       \\n\\n         [3]\\n        \\n\\n       It is now available from several sources, and is included as a bonus feature on a 1996\\n       \\n        BBC\\n       \\n       DVD. It is also included in the\\n       \\n        Vintage Cinema: Experiments in early film 1900s\\n       \\n       DVD.\\n      \"'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eight clock thursday morning arthur feel good french fries\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "\n",
    "def preprocess(sentence):\n",
    "    sentence = sentence.lower()\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokens = tokenizer.tokenize(sentence)\n",
    "    filtered_words = [w for w in tokens if not w in stopwords.words('english')]\n",
    "    return \" \".join(filtered_words)\n",
    "\n",
    "sentence = \"At eight \\n o'clock on Thursday morning Arthur didn't feel very good. French-Fries\"\n",
    "print(preprocess(sentence))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
