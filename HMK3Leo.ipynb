{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [1.1] Get the list of movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start downloading the html files with inside the urls of the documents we need!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://en.wikipedia.org/wiki/10_to_Midnight'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup = BeautifulSoup(open('C:/Users/leona/Desktop/ADMHMK-3/movies2.html'), \"html.parser\")\n",
    "soup.head()\n",
    "lst_a = soup.select('a')\n",
    "urls = []\n",
    "for i in lst_a:\n",
    "    urls.append(i.get('href'))\n",
    "urls[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://en.wikipedia.org/wiki/Love_by_the_Light_of_the_Moon'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup = BeautifulSoup(open('C:/Users/leona/Desktop/ADMHMK-3/movies1.html'), \"html.parser\")\n",
    "soup.head()\n",
    "lst_a = soup.select('a')\n",
    "lst_a\n",
    "for i in lst_a:\n",
    "    urls.append(i.get('href'))\n",
    "urls[10000]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://en.wikipedia.org/wiki/Z.P.G.'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup = BeautifulSoup(open('C:/Users/leona/Desktop/ADMHMK-3/movies3.html'), \"html.parser\")\n",
    "soup.head()\n",
    "lst_a = soup.select('a')\n",
    "lst_a\n",
    "for i in lst_a:\n",
    "    urls.append(i.get('href'))\n",
    "urls[20000] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://en.wikipedia.org/wiki/Whistle_(2003_film)'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls[29999]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have all 30.000 urls we need to save them in dictionary that we will access later when we want to print the urls in the output of the search engines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicturls = {}\n",
    "for i in range(len(urls)):\n",
    "    dicturls[i] = urls[i]\n",
    "with open('dicturls.json', 'w') as fp:\n",
    "    json.dump(dicturls, fp)\n",
    "with open(r\"C:\\Users\\leona\\Desktop\\ADMHMK-3\\dicturls.json\", 'r') as file:\n",
    "    data = file.read()\n",
    "dicturls = json.loads(data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://en.wikipedia.org/wiki/Whistle_(2003_film)'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dicturls[str(29999)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [1.2] Crawl Wikipedia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, avoiding any error,(there will not be, and knowing this I already saved in order the urls), we download on our pc the html files we need for our database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.error import URLError, HTTPError, ContentTooShortError\n",
    "import time\n",
    "def getwikipageshtml(urls):\n",
    "    k=0\n",
    "    for i in range(len(urls)):\n",
    "        try:\n",
    "            ur_l = requests.get(urls[i])\n",
    "            soup = BeautifulSoup(ur_l.content, 'html.parser')\n",
    "            soup = soup.prettify(\"utf-8\")   \n",
    "            stringa = 'Articles/article-'+str(k)+'.html'\n",
    "            k = k+1\n",
    "            Html_file= open(stringa, \"wb\")\n",
    "            Html_file.write(soup)\n",
    "            Html_file.close()\n",
    "        except(URLError,HTTPError, ContentTooShortError)  as e:\n",
    "            html = None\n",
    "        #time.sleep(0.001) #Actually for this task we don't need to stop anytime\n",
    "    return\n",
    "getwikipageshtml(urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [1.3] Parse downloaded pages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we access every html document and take out the informations we need to build our tsv files with info title, intro, plot, film_name, director, producer, writer, starring, music, release date, runtime, country, language, budget."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import io\n",
    "for i in range(30000):\n",
    "    filename = \"Articles/article-\"+str(i)+\".html\"\n",
    "    with open(filename, encoding=\"utf-8\") as f:\n",
    "        data = f.read()\n",
    "        soup = BeautifulSoup(data, 'html.parser')\n",
    "        #Now That I opened the file I have to look for the section asked\n",
    "        #first I take the title and clear him of spaces and the word -Wikipedia\n",
    "        titlepage = soup.title.string\n",
    "        titleonly = titlepage.split(\"- Wikipedia\")\n",
    "        titlepage = titleonly[0].strip()\n",
    "        #now I create empty string as intro and plot\n",
    "        intro = ''\n",
    "        plot = ''\n",
    "        #Now i searcvh the first paragraph that usually or is empty or is the intro\n",
    "        start = soup.find('p')\n",
    "        intro = start\n",
    "        intro1 = start.text\n",
    "        B = ''\n",
    "        #in B I put m,y limit for the paragraphs in the intro, because after this h2 there will always be the plot\n",
    "        B = intro.find_next_sibling('h2')\n",
    "        if(B!=None and B.find_next_sibling('p')):\n",
    "            C = B.find_next_sibling('p')\n",
    "            while(C != intro.find_next_sibling('p')): \n",
    "                intro1 = intro1 + intro.find_next_sibling('p').text\n",
    "                intro = intro.find_next_sibling('p')\n",
    "            plot = ''    \n",
    "            #then i do the same with the plot, so I start at B and end in the next h2\n",
    "            plot = B\n",
    "            plot1 = ''\n",
    "            compare = ''\n",
    "            if(B.find_next_sibling('h2')):\n",
    "                compare = B.find_next_sibling('h2')\n",
    "                compareto = compare.find_next_sibling('p')\n",
    "                while(compareto != plot.find_next_sibling('p')):\n",
    "                    plot1 = plot1 + plot.find_next_sibling('p').text\n",
    "                    #print(plot1)\n",
    "                    plot = plot.find_next_sibling('p')\n",
    "                    #if plot or intro are empty I put NA\n",
    "        if(intro1 == ''):\n",
    "            intro1 = \"NA\"\n",
    "        if plot1 == '':\n",
    "            plot1 = \"NA\"\n",
    "        #Now I start working on the other features\n",
    "        intro = intro1\n",
    "        plot = plot1\n",
    "        film_name = 'NA'\n",
    "        director = \"NA\"\n",
    "        producer = \"NA\"\n",
    "        writer = \"NA\"\n",
    "        starring = \"NA\"\n",
    "        music = \"NA\"\n",
    "        release_date = \"NA\"\n",
    "        runtime = \"NA\"\n",
    "        country = \"NA\"\n",
    "        language = \"NA\"\n",
    "        budget = \"NA\"\n",
    "#'film_name', 'director', 'producer','writer', 'starring', 'music', 'release date', 'runtime', 'country', 'language', 'budget'\n",
    "        for link in soup.find_all('tr'):\n",
    "            if soup.find('th',{'class': ['summary']})!= None:\n",
    "                    film_name = soup.find('th',{'class': ['summary']} ).text.strip()\n",
    "            if link.th:\n",
    "#I just check in the th and if I find the class I need I take the relative td. Some of them are inaccessible so the if link.td\n",
    "                if(link.th.text.strip() == 'Directed by'):\n",
    "                     director = link.td.text.strip()\n",
    "                elif(link.th.text.strip() == 'Produced by'):\n",
    "                      producer = link.td.text.strip()\n",
    "                elif(link.th.text.strip() == 'Written by'):\n",
    "                    writer = link.td.text.strip()\n",
    "                elif(link.th.text.strip() == 'Starring'):\n",
    "                    starring = link.td.text.strip()\n",
    "                elif(link.th.text.strip() == 'Music by'):\n",
    "                     music = link.td.text.strip()               \n",
    "                elif(link.th.text.strip() == 'Release date'):\n",
    "                    if link.td:\n",
    "                        release_date = link.td.text.strip()\n",
    "                elif(link.th.text.strip() == 'Running time'):\n",
    "                    runtime = link.td.text.strip()\n",
    "                elif(link.th.text.strip() == 'Country'):\n",
    "                    if link.td:\n",
    "                        country = link.td.text.strip()\n",
    "                elif(link.th.text.strip() == 'Language'):\n",
    "                    if link.td:\n",
    "                        language = link.td.text.strip()\n",
    "                elif(link.th.text.strip() == 'Budget'):\n",
    "                    budget = link.td.text.strip()\n",
    "#now I open the tsv files and create one for every film.        \n",
    "        tsvname = 'Tsvfiles/'+'film'+str(i)+'.tsv'\n",
    "        with io.open(tsvname, \"w\", encoding=\"utf-8\") as out_file:\n",
    "            tsv_writer = csv.writer(out_file, delimiter='\\t')\n",
    "            tsv_writer.writerow(['title','intro', 'plot', 'film_name', 'director', 'producer','writer', 'starring', 'music', 'release date', 'runtime', 'country', 'language', 'budget'])\n",
    "            tsv_writer.writerow([titlepage, intro, plot, film_name, director, producer, writer, starring, music, release_date, runtime, \n",
    "                 country, language, budget])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Whistle (2003 film)'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titlepage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n\\n\\n         What Became of Jack and Jill?\\n        \\n\\n       is a 1972 British\\n       \\n        horror film\\n       \\n       directed by\\n       \\n        Bill Bain\\n       \\n       and starring\\n       \\n        Mona Washbourne\\n       \\n       ,\\n       \\n        Paul Nicholas\\n       \\n       , and\\n       \\n        Vanessa Howard\\n       \\n       .\\n       \\n\\n         [1]\\n        \\n\\n       It was part of an abandoned attempt by\\n       \\n        Amicus Pictures\\n       \\n       to compete with\\n       \\n        Hammer Studios\\n       \\n       by breaking into the\\n       \\n        grindhouse\\n       \\n       market. Studio executives were ultimately too disturbed by the final product to release it under the Amicus name, and they sold the film to\\n       \\n        20th Century Fox\\n       \\n       .\\n      '"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this is just to try stuff."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we clean The files, so we first define a preprocess function to do it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io \n",
    "import nltk\n",
    "import csv\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    "stop_words = set(stopwords.words('english')) \n",
    "from nltk.stem import PorterStemmer \n",
    "\n",
    " \n",
    "ps = PorterStemmer() \n",
    "#the fuction preprocess the string as asked in the hmk\n",
    "def preprocess(sentence):\n",
    "    sentence = sentence.lower()\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokens = tokenizer.tokenize(sentence)\n",
    "    filtered_words = [ps.stem(w) for w in tokens if not w in stopwords.words('english')]\n",
    "    return \" \".join(filtered_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the function on every section of the tsv files, except for the tiles of the categories, so from the part 13 and clean them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(30000):\n",
    "    file1 = open('Tsvfiles/film'+str(i)+'.tsv', encoding=\"utf8\") \n",
    "    line = file1.read()# Use this to read file content as a stream: \n",
    "    words = line.split('\\t') \n",
    "    for j in range(13, len(words)):\n",
    "        words[j] = preprocess(words[j])\n",
    "        if j ==13:\n",
    "            #Here for the format of tsv files and my split('\\t') the word budget would always be in my title, so I take her out\n",
    "            words[j] = words[j].replace('budget ','')    \n",
    "    tsvname = \"Cleantsv/filmclean-\"+str(i)+'.tsv'\n",
    "    with io.open(tsvname, \"w\", encoding=\"utf-8\") as out_file:\n",
    "            tsv_writer = csv.writer(out_file, delimiter='\\t')\n",
    "            tsv_writer.writerow(['title','intro', 'plot', 'film_name', 'director', 'producer','writer', 'starring', 'music', 'release date', 'runtime', 'country', 'language', 'budget'])\n",
    "            tsv_writer.writerow(words[13:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'whistl 2003 film'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[13]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EX[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1.1) Create your index!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now from the clean intro and plots we start building the dictionary that will have \"index\":word, so we have a unique associatioin between a word in the dataset we care about and a number. Obviously we will save it as json file, as many other dictionaries that follow to be able to use them when we want in our search engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionar = {}\n",
    "k = 0\n",
    "for i in range(30000):\n",
    "    file1 = open(\"Cleantsv/filmclean-\"+str(i)+'.tsv', encoding=\"utf8\") \n",
    "    line = file1.read()# Use this to read file content as a stream: \n",
    "    #print(line)\n",
    "    words = line.split('\\t') \n",
    "    wordssplitted1 = words[14].split()\n",
    "    wordssplitted2 = words[15].split()\n",
    "    #print(wordssplitted1, wordssplitted2)\n",
    "    for i in wordssplitted1:\n",
    "        #print(type(i))\n",
    "        if i not in dictionar:\n",
    "            dictionar[i] = str(k)\n",
    "            k = k+1\n",
    "    for i in wordssplitted2:\n",
    "        #print(type(i))\n",
    "        if i not in dictionar:\n",
    "            dictionar[i] = str(k)\n",
    "            k = k+1\n",
    "#dictionar\n",
    "import json\n",
    "\n",
    "with open('Dictionary.json', 'w') as fp:\n",
    "    json.dump(dictionar, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'12741'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "with open(r\"C:\\Users\\leona\\Desktop\\ADMHMK-3\\Dictionary.json\", 'r') as file:\n",
    "    data = file.read()\n",
    "diction = json.loads(data)\n",
    "diction['1913']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(diction)\n",
    "type(diction['hom'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here is the inverted Dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we build the inverted dictionary that for each index has as value the nanme of the documents we know have the word that in the previous dictionary has that unique index. We save it as json file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dictionar2 = {}\n",
    "length = 0\n",
    "for i in range(30000):\n",
    "    file = \"Cleantsv/filmclean-\"+str(i)+'.tsv'\n",
    "    file1 = open(file, encoding=\"utf8\") \n",
    "    line = file1.read()# Use this to read file content as a stream: \n",
    "    #print(line)\n",
    "    words = line.split('\\t') \n",
    "    wordssplitted1 = words[14].split()\n",
    "    wordssplitted2 = words[15].split()\n",
    "    #print(wordssplitted1, wordssplitted2)\n",
    "    for j in wordssplitted1:\n",
    "        code = diction[j]\n",
    "        if code not in dictionar2:\n",
    "            dictionar2[code] = [file]\n",
    "        elif file not in dictionar2[code]:\n",
    "            dictionar2[code].append(file)\n",
    "    for j in wordssplitted2:\n",
    "        code = diction[j]\n",
    "        if code not in dictionar2:\n",
    "            dictionar2[code] = [file]\n",
    "        elif file not in dictionar2[code]:\n",
    "            dictionar2[code].append(file)\n",
    "#dictionar\n",
    "import json\n",
    "\n",
    "with open('Dictionary1.json', 'w') as fp:\n",
    "    json.dump(dictionar2, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "with open(r\"C:\\Users\\leona\\Desktop\\ADMHMK-3\\Dictionary1.json\", 'r') as file:\n",
    "    data = file.read()\n",
    "diction2 = json.loads(data)\n",
    "#dictions = pd.DataFrame(diction)\n",
    "#diction2['0']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114796"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diction['2019']\n",
    "len(diction2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1.2) Execute the query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First engine searchengine1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we remind some funcion we need to use and the vocabularies, so the following cell must not be run, but just used to remind the instruments we are using and defining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(r\"C:\\Users\\leona\\Desktop\\ADMHMK-3\\dicturls.json\", 'r') as file:\n",
    "    data = file.read()\n",
    "dicturls = json.loads(data) \n",
    "import pandas as pd\n",
    "with open(r\"C:\\Users\\leona\\Desktop\\ADMHMK-3\\Dictionary.json\", 'r') as file:\n",
    "    data = file.read()\n",
    "diction = json.loads(data)\n",
    "with open(r\"C:\\Users\\leona\\Desktop\\ADMHMK-3\\Dictionary1.json\", 'r') as file:\n",
    "    data = file.read()\n",
    "diction2 = json.loads(data)\n",
    "import io \n",
    "import nltk\n",
    "import csv\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    "stop_words = set(stopwords.words('english')) \n",
    "from nltk.stem import PorterStemmer \n",
    "\n",
    "\n",
    " \n",
    "ps = PorterStemmer() \n",
    "#the fuction preprocess the string as asked in the hmk\n",
    "def preprocess(sentence):\n",
    "    sentence = sentence.lower()\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokens = tokenizer.tokenize(sentence)\n",
    "    filtered_words = [ps.stem(w) for w in tokens if not w in stopwords.words('english')]\n",
    "    return \" \".join(filtered_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the code for the engine as a function that takes a input to analyze. It will give all the documents that will match all the words of the input inside their intro or plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ross\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Intro</th>\n",
       "      <th>Url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Superman III</td>\n",
       "      <td>Superman III               is a Briti...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Superman_III</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Footloose (1984 film)</td>\n",
       "      <td>Footloose               is a 1984 Ame...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Footloose_(1984_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Protocol (film)</td>\n",
       "      <td>Protocol               is a 1984 Amer...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Protocol_(film)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Splash (film)</td>\n",
       "      <td>Splash               is a 1984 Americ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Splash_(film)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Friday the 13th: A New Beginning</td>\n",
       "      <td>Friday the 13th: A New Beginning     ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Friday_the_13th:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>Turning Paige</td>\n",
       "      <td>Turning Paige               is a 2001...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Turning_Paige</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>The Saddest Music in the World</td>\n",
       "      <td>The Saddest Music in the World       ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Saddest_Musi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>Goon (film)</td>\n",
       "      <td>Goon               is a 2011 Canadian...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Goon_(film)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>Charming (film)</td>\n",
       "      <td>Charming               is a 2018 Cana...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Charming_(film)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>Goon: Last of the Enforcers</td>\n",
       "      <td>Goon: Last of the Enforcers          ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Goon:_Last_of_th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>356 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Title  \\\n",
       "0                        Superman III   \n",
       "1               Footloose (1984 film)   \n",
       "2                     Protocol (film)   \n",
       "3                       Splash (film)   \n",
       "4    Friday the 13th: A New Beginning   \n",
       "..                                ...   \n",
       "351                     Turning Paige   \n",
       "352    The Saddest Music in the World   \n",
       "353                       Goon (film)   \n",
       "354                   Charming (film)   \n",
       "355       Goon: Last of the Enforcers   \n",
       "\n",
       "                                                 Intro  \\\n",
       "0             Superman III               is a Briti...   \n",
       "1             Footloose               is a 1984 Ame...   \n",
       "2             Protocol               is a 1984 Amer...   \n",
       "3             Splash               is a 1984 Americ...   \n",
       "4             Friday the 13th: A New Beginning     ...   \n",
       "..                                                 ...   \n",
       "351           Turning Paige               is a 2001...   \n",
       "352           The Saddest Music in the World       ...   \n",
       "353           Goon               is a 2011 Canadian...   \n",
       "354           Charming               is a 2018 Cana...   \n",
       "355           Goon: Last of the Enforcers          ...   \n",
       "\n",
       "                                                   Url  \n",
       "0           https://en.wikipedia.org/wiki/Superman_III  \n",
       "1    https://en.wikipedia.org/wiki/Footloose_(1984_...  \n",
       "2        https://en.wikipedia.org/wiki/Protocol_(film)  \n",
       "3          https://en.wikipedia.org/wiki/Splash_(film)  \n",
       "4    https://en.wikipedia.org/wiki/Friday_the_13th:...  \n",
       "..                                                 ...  \n",
       "351        https://en.wikipedia.org/wiki/Turning_Paige  \n",
       "352  https://en.wikipedia.org/wiki/The_Saddest_Musi...  \n",
       "353          https://en.wikipedia.org/wiki/Goon_(film)  \n",
       "354      https://en.wikipedia.org/wiki/Charming_(film)  \n",
       "355  https://en.wikipedia.org/wiki/Goon:_Last_of_th...  \n",
       "\n",
       "[356 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#HERE i DEFINE THE FUCTION TO RECEIVE THE DATASET, GIVEN AN INPUT\n",
    "y = list(input().split())\n",
    "def searchengine1(y):\n",
    "    for i in range(len(y)):\n",
    "        y[i]= preprocess(str(y[i]))\n",
    "    #Now I tranform the list of input in a list of the codes in the dictiionary based on the input\n",
    "    yfinal=[] #use this because some words have no match in the vocabulary\n",
    "    for i in range(len(y)):\n",
    "        #print(y[i])\n",
    "        if y[i] in diction:\n",
    "            yfinal.append(diction[y[i]])\n",
    "    #Now I have to search inside the lists of values from the keys i foundb and see if some films match in the various keys.\n",
    "    if  len(yfinal)<len(y):\n",
    "        return print('We are sorry there are no films, in my database, that match ALL the words you gave me !(')\n",
    "    else:\n",
    "        starting_values = diction2[yfinal[0]]\n",
    "        final_values = starting_values.copy()\n",
    "        for codes in range(1,len(yfinal)):\n",
    "            new = []\n",
    "            for film in final_values:\n",
    "                if film in diction2[yfinal[codes]]:\n",
    "                    new.append(film)\n",
    "            final_values = new\n",
    "        megaDataframe = pd.DataFrame(columns = ['Title', 'Intro', 'Url'])\n",
    "        if not final_values:\n",
    "            return print(\"Wow no film matched my quiery, I need more films to compare!\")\n",
    "        else:           \n",
    "            k=0\n",
    "            for document in final_values:\n",
    "                totakeurl = document.replace('Cleantsv/filmclean-','')\n",
    "                totakeurl = str(int(totakeurl.replace('.tsv', '')))\n",
    "                url = dicturls[totakeurl]\n",
    "                temporary = pd.read_csv('Tsvfiles/'+'film'+(totakeurl)+'.tsv',delimiter='\\t' )\n",
    "                title = temporary['title'][0]\n",
    "                intro =  temporary['intro'][0].replace('\\r\\n','')\n",
    "                new_row = [title, intro, url]\n",
    "                megaDataframe.loc[k]=new_row\n",
    "                k=k+1\n",
    "            return megaDataframe\n",
    "A = searchengine1(y)\n",
    "A\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batman robin \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Intro</th>\n",
       "      <th>Url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Batman (1989 film)</td>\n",
       "      <td>Batman               is a 1989 Americ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Batman_(1989_film)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Batman Forever</td>\n",
       "      <td>Batman Forever               is a 199...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Batman_Forever</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>List of Baywatch episodes</td>\n",
       "      <td>Below is a list of all the episodes fro...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Baywatch_the_Mov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Batman &amp; Robin (film)</td>\n",
       "      <td>Batman &amp; Robin               is a 199...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Batman_%26_Robin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Batman Begins</td>\n",
       "      <td>Batman Begins               is a 2005...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Batman_Begins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The Number 23</td>\n",
       "      <td>The Number 23               is a 2007...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Number_23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Arthur (2011 film)</td>\n",
       "      <td>Arthur               is a 2011 Americ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Arthur_(2011_film)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Jay &amp; Silent Bob's Super Groovy Cartoon Movie!</td>\n",
       "      <td>Jay &amp; Silent Bob’s Super Groovy Carto...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Jay_%26_Silent_B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Movie 43</td>\n",
       "      <td>Movie 43               is a 2013 Amer...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Movie_43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The Lego Batman Movie</td>\n",
       "      <td>The Lego Batman Movie               i...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Lego_Batman_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Wonder Woman (2017 film)</td>\n",
       "      <td>Wonder Woman               is a 2017 ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Wonder_Woman_(20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Batman (serial)</td>\n",
       "      <td>Batman               (or             ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Batman_(serial)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Batman and Robin (serial)</td>\n",
       "      <td>New Adventures of Batman and Robin, t...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Batman_and_Robin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Batman (1966 film)</td>\n",
       "      <td>Batman               (also known as  ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Batman_(1966_film)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>The Super Cops</td>\n",
       "      <td>The Super Cops               is a 197...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Super_Cops</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Title  \\\n",
       "0                               Batman (1989 film)   \n",
       "1                                   Batman Forever   \n",
       "2                        List of Baywatch episodes   \n",
       "3                            Batman & Robin (film)   \n",
       "4                                    Batman Begins   \n",
       "5                                    The Number 23   \n",
       "6                               Arthur (2011 film)   \n",
       "7   Jay & Silent Bob's Super Groovy Cartoon Movie!   \n",
       "8                                         Movie 43   \n",
       "9                            The Lego Batman Movie   \n",
       "10                        Wonder Woman (2017 film)   \n",
       "11                                 Batman (serial)   \n",
       "12                       Batman and Robin (serial)   \n",
       "13                              Batman (1966 film)   \n",
       "14                                  The Super Cops   \n",
       "\n",
       "                                                Intro  \\\n",
       "0            Batman               is a 1989 Americ...   \n",
       "1            Batman Forever               is a 199...   \n",
       "2          Below is a list of all the episodes fro...   \n",
       "3            Batman & Robin               is a 199...   \n",
       "4            Batman Begins               is a 2005...   \n",
       "5            The Number 23               is a 2007...   \n",
       "6            Arthur               is a 2011 Americ...   \n",
       "7            Jay & Silent Bob’s Super Groovy Carto...   \n",
       "8            Movie 43               is a 2013 Amer...   \n",
       "9            The Lego Batman Movie               i...   \n",
       "10           Wonder Woman               is a 2017 ...   \n",
       "11           Batman               (or             ...   \n",
       "12           New Adventures of Batman and Robin, t...   \n",
       "13           Batman               (also known as  ...   \n",
       "14           The Super Cops               is a 197...   \n",
       "\n",
       "                                                  Url  \n",
       "0    https://en.wikipedia.org/wiki/Batman_(1989_film)  \n",
       "1        https://en.wikipedia.org/wiki/Batman_Forever  \n",
       "2   https://en.wikipedia.org/wiki/Baywatch_the_Mov...  \n",
       "3   https://en.wikipedia.org/wiki/Batman_%26_Robin...  \n",
       "4         https://en.wikipedia.org/wiki/Batman_Begins  \n",
       "5         https://en.wikipedia.org/wiki/The_Number_23  \n",
       "6    https://en.wikipedia.org/wiki/Arthur_(2011_film)  \n",
       "7   https://en.wikipedia.org/wiki/Jay_%26_Silent_B...  \n",
       "8              https://en.wikipedia.org/wiki/Movie_43  \n",
       "9   https://en.wikipedia.org/wiki/The_Lego_Batman_...  \n",
       "10  https://en.wikipedia.org/wiki/Wonder_Woman_(20...  \n",
       "11      https://en.wikipedia.org/wiki/Batman_(serial)  \n",
       "12  https://en.wikipedia.org/wiki/Batman_and_Robin...  \n",
       "13   https://en.wikipedia.org/wiki/Batman_(1966_film)  \n",
       "14       https://en.wikipedia.org/wiki/The_Super_Cops  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = list(input().split())\n",
    "searchengine1(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sky vanilla\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Intro</th>\n",
       "      <th>Url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Vanilla Sky</td>\n",
       "      <td>Vanilla Sky               is a 2001 A...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Vanilla_Sky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Knight and Day</td>\n",
       "      <td>Knight and Day               is a 201...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Knight_and_Day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>There's Always Vanilla</td>\n",
       "      <td>There's Always Vanilla               ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/There%27s_Always...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Title                                              Intro  \\\n",
       "0             Vanilla Sky           Vanilla Sky               is a 2001 A...   \n",
       "1          Knight and Day           Knight and Day               is a 201...   \n",
       "2  There's Always Vanilla           There's Always Vanilla               ...   \n",
       "\n",
       "                                                 Url  \n",
       "0          https://en.wikipedia.org/wiki/Vanilla_Sky  \n",
       "1       https://en.wikipedia.org/wiki/Knight_and_Day  \n",
       "2  https://en.wikipedia.org/wiki/There%27s_Always...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = list(input().split())\n",
    "searchengine1(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2) Conjunctive query & Ranking score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building of the second search engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we create a list with inside strings that represent intro and plot of every document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Docum_and_words = []\n",
    "for i in range(30000):\n",
    "    file = \"Cleantsv/filmclean-\"+str(i)+'.tsv'\n",
    "    file1 = open(file, encoding=\"utf8\") \n",
    "    line = file1.read()# Use this to read file content as a stream: \n",
    "    #print(line)\n",
    "    words = line.split('\\t') \n",
    "    wordssplitted1 = words[14].split()\n",
    "    wordssplitted2 = words[15].split()\n",
    "    words = wordssplitted1+wordssplitted2\n",
    "    A = \" \".join(words)\n",
    "    Docum_and_words.append(A)\n",
    "#print(Docum_and_words) \n",
    "#I have the lis of documents with intro and plot\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define two function to get the tf and the number of documents containing a word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from textblob import TextBlob as tb\n",
    "def tf(word, doc):\n",
    "    return doc.count(word) / len(doc)\n",
    "\n",
    "def n_containing(word, doclist):\n",
    "    return sum(1 for doc in doclist if word in doc.split())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create dictionary with idf to save computational costs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Third dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some preliminary declarations to run the code at any moment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "Docum_and_words = []\n",
    "for i in range(30000):\n",
    "    file = \"Cleantsv/filmclean-\"+str(i)+'.tsv'\n",
    "    file1 = open(file, encoding=\"utf8\") \n",
    "    line = file1.read()\n",
    "    words = line.split('\\t') \n",
    "    wordssplitted1 = words[14].split()\n",
    "    wordssplitted2 = words[15].split()\n",
    "    words = wordssplitted1+wordssplitted2\n",
    "    A = \" \".join(words)\n",
    "    Docum_and_words.append(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'10 midnight 1983 american crime horror thriller film 3 direct j lee thompson screenplay origin written william robert film star charl bronson lead role support cast includ lisa eilbach andrew steven gene davi geoffrey lewi wilford brimley 10 midnight releas citi film subsidiari cannon film american cinema march 11 1983 warren staci gene davi young offic equip repairman kill women reject sexual advanc attempt flirt alway seen creepi women result frequent reject 4 first victim betti june gilbert offic worker acquaint track wood area observ sex boyfriend ambush coupl kill boyfriend give chase nake woman catch stab death 4 two lo angel polic detect leo kessler charl bronson paul mcann andrew steven investig murder kessler season veteran forc mcann consider younger 4 staci avoid prosecut construct sound alibi assault victim nake except pair latex glove hide fingerprint thu minim evid lauri kessler lisa eilbach daughter leo acquaint victim student nurs becom target killer 4 mcann refus go along kessler plant evid order frame suspect staci goe anoth rampag kill three nurs student friend kessler daughter eventu caught stark nake street staci boast say thing prove crazi hear voic order thing etc one day back street kessler well whole fuck world hear kessler repli shoot staci forehead execut leav consider asid kessler stand bodi surround polic'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Docum_and_words[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"C:\\Users\\leona\\Desktop\\ADMHMK-3\\dicturls.json\", 'r') as file:\n",
    "    data = file.read()\n",
    "dicturls = json.loads(data) \n",
    "with open(r\"C:\\Users\\leona\\Desktop\\ADMHMK-3\\Dictionary.json\", 'r') as file:\n",
    "    data = file.read()\n",
    "diction = json.loads(data) #first dict with every word and a unique value\n",
    "with open(r\"C:\\Users\\leona\\Desktop\\ADMHMK-3\\Dictionary1.json\", 'r') as file:\n",
    "    data = file.read()\n",
    "diction2 = json.loads(data)#first inverted dict with number and list of document with a word that has that number in diction\n",
    "import math\n",
    "from textblob import TextBlob as tb\n",
    "def tf(word, doc):\n",
    "    return doc.count(word) / len(doc)\n",
    "def n_containing(word, doclist):\n",
    "    return sum(1 for doc in doclist if word in doc.split())\n",
    "\n",
    "def idf(word, doclist):\n",
    "    return math.log(len(doclist) / float(n_containing(word, doclist)))\n",
    "\n",
    "def tfidf(word, doc, doclist):\n",
    "    return (tf(word, doc) * idf(word, doclist))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a dictionary with inside associated to every word in diction(the one that matched indexes and words) the number of documents it is in on the 30.000 of the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncontain = {}\n",
    "for i in diction:\n",
    "    refer = diction[i]\n",
    "    #print(i)\n",
    "    ncontain[i] = len(diction2[refer])\n",
    "with open('ncontain.json', 'w') as fp:\n",
    "    json.dump(ncontain, fp)\n",
    "with open(r\"C:\\Users\\leona\\Desktop\\ADMHMK-3\\ncontain.json\", 'r') as file:\n",
    "    data = file.read()\n",
    "ncontain = json.loads(data) #first dict with every word and a unique value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114796"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ncontain.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "idfdict is the dictionary that if you select a word will give you its idf. We save it as a json file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "idfdict = {}\n",
    "for i in ncontain:\n",
    "    idfdict[i]=math.log(30000 / ncontain[i])\n",
    "with open('idfdict.json', 'w') as fp:\n",
    "    json.dump(idfdict, fp)\n",
    "with open(r\"C:\\Users\\leona\\Desktop\\ADMHMK-3\\idfdict.json\", 'r') as file:\n",
    "    data = file.read()\n",
    "idfdict = json.loads(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"C:\\Users\\leona\\Desktop\\ADMHMK-3\\idfdict.json\", 'r') as file:\n",
    "    data = file.read()\n",
    "idfdict = json.loads(data)\n",
    "#idfdict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2.1) Inverted index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second dictionary with the tf-idf values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are ready to do very easily the dictionary with key : ([document, tf-idf]) because we already saved the idf in a dictioonary so the next code will be pretty fast in creating the dict. We save it a json file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dictionar3 = {}\n",
    "#length = 0\n",
    "for i in range(30000):\n",
    "    file = \"Cleantsv/filmclean-\"+str(i)+'.tsv'\n",
    "    temp = []\n",
    "    for j in Docum_and_words[i].split():\n",
    "            if j not in temp:\n",
    "                #dicus = {}\n",
    "                code = diction[j]\n",
    "                value = tf(j, Docum_and_words[i].split())*idfdict[j]\n",
    "                li = [file, value]\n",
    "                if code not in dictionar3:\n",
    "                    #dicus[file]=value\n",
    "                    dictionar3[code] = [li]\n",
    "                else:   \n",
    "                    #dicus[file]=value\n",
    "                    dictionar3[code].append(li)\n",
    "                temp.append(j)\n",
    "import json\n",
    "\n",
    "with open('Dictionary2.json', 'w') as fp:\n",
    "    json.dump(dictionar3, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114796"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dictionar3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now I import the files I need and prepare the code for the search engine2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "with open(r\"C:\\Users\\leona\\Desktop\\ADMHMK-3\\dicturls.json\", 'r') as file:\n",
    "    data = file.read()\n",
    "dicturls = json.loads(data) \n",
    "with open(r\"C:\\Users\\leona\\Desktop\\ADMHMK-3\\Dictionary.json\", 'r') as file:\n",
    "    data = file.read()\n",
    "diction = json.loads(data) #first dict with every word and a unique value\n",
    "with open(r\"C:\\Users\\leona\\Desktop\\ADMHMK-3\\Dictionary1.json\", 'r') as file:\n",
    "    data = file.read()\n",
    "diction2 = json.loads(data)#first inverted dict with number and list of document with a word that has that number in diction\n",
    "with open(r\"C:\\Users\\leona\\Desktop\\ADMHMK-3\\ncontain.json\", 'r') as file:\n",
    "    data = file.read()\n",
    "ncontain = json.loads(data) #dict with number of times a word appear in all the cod\n",
    "with open(r\"C:\\Users\\leona\\Desktop\\ADMHMK-3\\idfdict.json\", 'r') as file:\n",
    "    data = file.read()\n",
    "idfdict = json.loads(data) #dict with the idf for every word\n",
    "with open(r\"C:\\Users\\leona\\Desktop\\ADMHMK-3\\Dictionary2.json\", 'r') as file:\n",
    "    data = file.read()\n",
    "diction3 = json.loads(data) #second inverted dictionary wit doc and tfidf for eevry word\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ASbout copsine similarity I have to take the tfidf of my k best document and multipèly singularly it with the values of the quiery that are tf(relative of the quiery)*idf(relative to my documents for each component)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The query entered by the user can also be represented as a vector. We will calculate the TF*IDF for the query\n",
    "\n",
    "TF\tIDF\tTF*IDF\n",
    "life\t0.5\t1.405507153\t0.702753576\n",
    "learning\t0.5\t1.405507153\t0.702753576\n",
    "Let us now calculate the cosine similarity of the query and Document1. You can do the calculation using this tool.\n",
    "\n",
    "Cosine Similarity(Query,Document1) = Dot product(Query, Document1) / ||Query|| * ||Document1||\n",
    "\n",
    "Dot product(Query, Document1) \n",
    "     = ((0.702753576) * (0.140550715) + (0.702753576)*(0.140550715))\n",
    "     = 0.197545035151\n",
    "\n",
    "||Query|| = sqrt((0.702753576)2 + (0.702753576)2) = 0.993843638185\n",
    "\n",
    "||Document1|| = sqrt((0.140550715)2 + (0.140550715)2) = 0.198768727354\n",
    "\n",
    "Cosine Similarity(Query, Document) = 0.197545035151 / (0.993843638185) * (0.198768727354)\n",
    "                                        = 0.197545035151 / 0.197545035151\n",
    "                                        = 1\n",
    "        \n",
    "https://janav.wordpress.com/2013/10/27/tf-idf-and-cosine-similarity/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I prepare the code for the search engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here there are the functions to easily compute the cosine similarity given two vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as pyplot\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "def simple_dot(a, b):\n",
    "    dsum = 0.\n",
    "    for ((idx,), val) in np.ndenumerate(a):\n",
    "        dsum += float(val) * float(b[idx])\n",
    "    return dsum\n",
    "\n",
    "def l2_norm(a):\n",
    "    return math.sqrt(np.dot(a, a))\n",
    "\n",
    "def cosine_similarity(a, b):\n",
    "    return np.dot(a,b) / (l2_norm(a)* l2_norm(b))\n",
    "np.dot([1,2],[3,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I remind that Docume_and_words is a list with inside every intro-plot(preprocessed) for every document, so I can just accees to it for my research."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "Docum_and_words = []\n",
    "for i in range(30000):\n",
    "    file = \"Cleantsv/filmclean-\"+str(i)+'.tsv'\n",
    "    file1 = open(file, encoding=\"utf8\") \n",
    "    line = file1.read()\n",
    "    words = line.split('\\t') \n",
    "    wordssplitted1 = words[14].split()\n",
    "    wordssplitted2 = words[15].split()\n",
    "    words = wordssplitted1+wordssplitted2\n",
    "    A = \" \".join(words)\n",
    "    Docum_and_words.append(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io \n",
    "import nltk\n",
    "import csv\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    "stop_words = set(stopwords.words('english')) \n",
    "from nltk.stem import PorterStemmer \n",
    "\n",
    " \n",
    "ps = PorterStemmer() \n",
    "#the fuction preprocess the string as asked in the hmk\n",
    "def preprocess(sentence):\n",
    "    sentence = sentence.lower()\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokens = tokenizer.tokenize(sentence)\n",
    "    filtered_words = [ps.stem(w) for w in tokens if not w in stopwords.words('english')]\n",
    "    return \" \".join(filtered_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2.2) Execute the query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ENGINE2!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I build the search engine2. The heap sorting is in the 'cossim' list that will have all the possible values of cosine similarity we have found for the query. We will print the dataframe with the best 20 results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WESTERN 1980 film hollywood\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Intro</th>\n",
       "      <th>Url</th>\n",
       "      <th>Similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stir Crazy (film)</td>\n",
       "      <td>Stir Crazy               is a 1980 Am...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Stir_Crazy_(film)</td>\n",
       "      <td>0.9688606777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Heaven's Gate (film)</td>\n",
       "      <td>Heaven's Gate               is a 1980...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Heaven%27s_Gate_...</td>\n",
       "      <td>0.9436166444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Title                                              Intro  \\\n",
       "0     Stir Crazy (film)           Stir Crazy               is a 1980 Am...   \n",
       "1  Heaven's Gate (film)           Heaven's Gate               is a 1980...   \n",
       "\n",
       "                                                 Url    Similarity  \n",
       "0    https://en.wikipedia.org/wiki/Stir_Crazy_(film)  0.9688606777  \n",
       "1  https://en.wikipedia.org/wiki/Heaven%27s_Gate_...  0.9436166444  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#HERE i DEFINE THE FUCTION TO RECEIVE THE DATASET, GIVEN AN INPUT\n",
    "import heapq as hq\n",
    "def tf(word, doc):\n",
    "    return doc.count(word) / len(doc)\n",
    "y = list(input().split())\n",
    "def searchengine2(y):\n",
    "    for i in range(len(y)):\n",
    "        y[i]= preprocess(str(y[i]))\n",
    "    #Now I tranform the list of input in a list of the codes in the dictiionary based on the input\n",
    "    yfinal=[] #use this because some words have no match in the vocabulary\n",
    "    for i in range(len(y)):\n",
    "        #print(y[i])\n",
    "        if y[i] in diction:\n",
    "            yfinal.append(diction[y[i]])\n",
    "    #Now I have to search inside the lists of values from the keys i foundb and see if some films match in the various keys.\n",
    "    if  len(yfinal)<len(y):\n",
    "        return print('We are sorry there are no films, in my database, that match ALL the words you gave me !(')\n",
    "    else:\n",
    "        starting_values = diction2[yfinal[0]]\n",
    "        final_values = starting_values.copy()\n",
    "        for codes in range(1,len(yfinal)):\n",
    "            new = []\n",
    "            for film in final_values:\n",
    "                if film in diction2[yfinal[codes]]:\n",
    "                    new.append(film)\n",
    "            final_values = new\n",
    "        megaDataframe = pd.DataFrame(columns = ['Title', 'Intro', 'Url', 'Similarity'])\n",
    "        if not final_values:\n",
    "            return print(\"Wow no film matched my quiery, I need more films to compare!\")\n",
    "        else:  \n",
    "            lstofl = []\n",
    "            #here there is a lstofl that has vectors associated with every document, in order of final_values\n",
    "            for film in final_values:\n",
    "                item = []\n",
    "                for code in yfinal:\n",
    "                    for value in diction3[code]:\n",
    "                        if film in value:\n",
    "                            item.append(value[1])\n",
    "                            break\n",
    "                lstofl.append(item) \n",
    "            #Now I have to create the inquiry vector and get the cosine similarity of beetween it and every component of lstofl \n",
    "            query = []\n",
    "            for i in y:\n",
    "                query.append(tf(i,y)*idfdict[i])\n",
    "            cossim = []\n",
    "            for vector in lstofl:\n",
    "                cossim.append(cosine_similarity(query, vector))\n",
    "            #print(cossim) #the cosine similariotyb in order of apparition of my document\n",
    "            dict_sim = {}\n",
    "            for indx in range(len(cossim)):\n",
    "                sim = cossim[indx]\n",
    "                if sim not in dict_sim:\n",
    "                    dict_sim[sim]=[final_values[indx]]\n",
    "                else:\n",
    "                    dict_sim[sim].append(final_values[indx])\n",
    "            Peak = 20\n",
    "            #HERE THE HEAP ALGORITHM\n",
    "            to_select = hq.nlargest(Peak, cossim)   \n",
    "            k=0\n",
    "            #Now i have the name key(cossim) and values(docum) and I have to take the first 15 of them.\n",
    "            for i in to_select:\n",
    "                if(k<Peak):\n",
    "                    for document in dict_sim[i]:\n",
    "                            if(k>Peak):\n",
    "                                return megaDataframe\n",
    "                            totakeurl = document.replace('Cleantsv/filmclean-','')\n",
    "                            totakeurl = str(int(totakeurl.replace('.tsv', '')))\n",
    "                            url = dicturls[totakeurl]\n",
    "                            Similarity = format(i, '.10g')\n",
    "                            temporary = pd.read_csv('Tsvfiles/'+'film'+(totakeurl)+'.tsv',delimiter='\\t' )\n",
    "                            title = temporary['title'][0]\n",
    "                            intro =  temporary['intro'][0].replace('\\r\\n','')\n",
    "                            new_row = [title, intro, url, Similarity]\n",
    "                            megaDataframe.loc[k]=new_row\n",
    "                            k=k+1\n",
    "            return  megaDataframe\n",
    "A = searchengine2(y)\n",
    "A\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see some examples! As we use simple strings and with not many repetitions it's possible more than one value will be one, as we will put a more difficult query we will have lower similarity probably."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LIGHT light dark light\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Intro</th>\n",
       "      <th>Url</th>\n",
       "      <th>Similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Warlock: The Armageddon</td>\n",
       "      <td>Warlock: The Armageddon              ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Warlock:_The_Arm...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Solitaire Man</td>\n",
       "      <td>The Solitaire Man               is a ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Solitaire_Man</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Atomic Submarine</td>\n",
       "      <td>The Atomic Submarine               is...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Atomic_Subma...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Warlock: The Armageddon</td>\n",
       "      <td>Warlock: The Armageddon              ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Warlock:_The_Arm...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Solitaire Man</td>\n",
       "      <td>The Solitaire Man               is a ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Solitaire_Man</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The Atomic Submarine</td>\n",
       "      <td>The Atomic Submarine               is...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Atomic_Subma...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Warlock: The Armageddon</td>\n",
       "      <td>Warlock: The Armageddon              ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Warlock:_The_Arm...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The Solitaire Man</td>\n",
       "      <td>The Solitaire Man               is a ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Solitaire_Man</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The Atomic Submarine</td>\n",
       "      <td>The Atomic Submarine               is...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Atomic_Subma...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Megiddo: The Omega Code 2</td>\n",
       "      <td>Megiddo: The Omega Code 2            ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Megiddo:_The_Ome...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Alien Abduction (2014 film)</td>\n",
       "      <td>Alien Abduction               (also k...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Alien_Abduction_...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Madeline (1998 film)</td>\n",
       "      <td>Nigel Hawthorne</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Madeline_(1998_f...</td>\n",
       "      <td>0.9988400935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Lulu on the Bridge</td>\n",
       "      <td>Lulu on the Bridge               is a...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Lulu_on_the_Bridge</td>\n",
       "      <td>0.9988400935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Gabriel Over the White House</td>\n",
       "      <td>Gabriel Over the White House         ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Gabriel_Over_the...</td>\n",
       "      <td>0.9970045216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Monsters (2010 film)</td>\n",
       "      <td>Monsters               is a 2010 Brit...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Monsters_(2010_f...</td>\n",
       "      <td>0.9956368204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>The Hound of the Baskervilles (1959 film)</td>\n",
       "      <td>The Hound of the Baskervilles        ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Hound_of_the...</td>\n",
       "      <td>0.9956368204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Heartless (2009 film)</td>\n",
       "      <td>Heartless               is a 2009    ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Heartless_(2009_...</td>\n",
       "      <td>0.9956368204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>The Hound of the Baskervilles (1959 film)</td>\n",
       "      <td>The Hound of the Baskervilles        ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Hound_of_the...</td>\n",
       "      <td>0.9956368204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Heartless (2009 film)</td>\n",
       "      <td>Heartless               is a 2009    ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Heartless_(2009_...</td>\n",
       "      <td>0.9956368204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Mr. Destiny</td>\n",
       "      <td>Mr. Destiny               is a 1990 A...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Mr._Destiny</td>\n",
       "      <td>0.9956368204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Shadow of the Vampire</td>\n",
       "      <td>Shadow of the Vampire               i...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Shadow_of_the_Va...</td>\n",
       "      <td>0.9956368204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Title  \\\n",
       "0                     Warlock: The Armageddon   \n",
       "1                           The Solitaire Man   \n",
       "2                        The Atomic Submarine   \n",
       "3                     Warlock: The Armageddon   \n",
       "4                           The Solitaire Man   \n",
       "5                        The Atomic Submarine   \n",
       "6                     Warlock: The Armageddon   \n",
       "7                           The Solitaire Man   \n",
       "8                        The Atomic Submarine   \n",
       "9                   Megiddo: The Omega Code 2   \n",
       "10                Alien Abduction (2014 film)   \n",
       "11                       Madeline (1998 film)   \n",
       "12                         Lulu on the Bridge   \n",
       "13               Gabriel Over the White House   \n",
       "14                       Monsters (2010 film)   \n",
       "15  The Hound of the Baskervilles (1959 film)   \n",
       "16                      Heartless (2009 film)   \n",
       "17  The Hound of the Baskervilles (1959 film)   \n",
       "18                      Heartless (2009 film)   \n",
       "19                                Mr. Destiny   \n",
       "20                      Shadow of the Vampire   \n",
       "\n",
       "                                                Intro  \\\n",
       "0            Warlock: The Armageddon              ...   \n",
       "1            The Solitaire Man               is a ...   \n",
       "2            The Atomic Submarine               is...   \n",
       "3            Warlock: The Armageddon              ...   \n",
       "4            The Solitaire Man               is a ...   \n",
       "5            The Atomic Submarine               is...   \n",
       "6            Warlock: The Armageddon              ...   \n",
       "7            The Solitaire Man               is a ...   \n",
       "8            The Atomic Submarine               is...   \n",
       "9            Megiddo: The Omega Code 2            ...   \n",
       "10           Alien Abduction               (also k...   \n",
       "11                        Nigel Hawthorne               \n",
       "12           Lulu on the Bridge               is a...   \n",
       "13           Gabriel Over the White House         ...   \n",
       "14           Monsters               is a 2010 Brit...   \n",
       "15           The Hound of the Baskervilles        ...   \n",
       "16           Heartless               is a 2009    ...   \n",
       "17           The Hound of the Baskervilles        ...   \n",
       "18           Heartless               is a 2009    ...   \n",
       "19           Mr. Destiny               is a 1990 A...   \n",
       "20           Shadow of the Vampire               i...   \n",
       "\n",
       "                                                  Url    Similarity  \n",
       "0   https://en.wikipedia.org/wiki/Warlock:_The_Arm...             1  \n",
       "1     https://en.wikipedia.org/wiki/The_Solitaire_Man             1  \n",
       "2   https://en.wikipedia.org/wiki/The_Atomic_Subma...             1  \n",
       "3   https://en.wikipedia.org/wiki/Warlock:_The_Arm...             1  \n",
       "4     https://en.wikipedia.org/wiki/The_Solitaire_Man             1  \n",
       "5   https://en.wikipedia.org/wiki/The_Atomic_Subma...             1  \n",
       "6   https://en.wikipedia.org/wiki/Warlock:_The_Arm...             1  \n",
       "7     https://en.wikipedia.org/wiki/The_Solitaire_Man             1  \n",
       "8   https://en.wikipedia.org/wiki/The_Atomic_Subma...             1  \n",
       "9   https://en.wikipedia.org/wiki/Megiddo:_The_Ome...             1  \n",
       "10  https://en.wikipedia.org/wiki/Alien_Abduction_...             1  \n",
       "11  https://en.wikipedia.org/wiki/Madeline_(1998_f...  0.9988400935  \n",
       "12   https://en.wikipedia.org/wiki/Lulu_on_the_Bridge  0.9988400935  \n",
       "13  https://en.wikipedia.org/wiki/Gabriel_Over_the...  0.9970045216  \n",
       "14  https://en.wikipedia.org/wiki/Monsters_(2010_f...  0.9956368204  \n",
       "15  https://en.wikipedia.org/wiki/The_Hound_of_the...  0.9956368204  \n",
       "16  https://en.wikipedia.org/wiki/Heartless_(2009_...  0.9956368204  \n",
       "17  https://en.wikipedia.org/wiki/The_Hound_of_the...  0.9956368204  \n",
       "18  https://en.wikipedia.org/wiki/Heartless_(2009_...  0.9956368204  \n",
       "19          https://en.wikipedia.org/wiki/Mr._Destiny  0.9956368204  \n",
       "20  https://en.wikipedia.org/wiki/Shadow_of_the_Va...  0.9956368204  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = list(input().split())\n",
    "searchengine2(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batman sleep\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Intro</th>\n",
       "      <th>Url</th>\n",
       "      <th>Similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Inception</td>\n",
       "      <td>Inception               is a 2010    ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Inception</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Arthur (2011 film)</td>\n",
       "      <td>Arthur               is a 2011 Americ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Arthur_(2011_film)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Inception</td>\n",
       "      <td>Inception               is a 2010    ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Inception</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arthur (2011 film)</td>\n",
       "      <td>Arthur               is a 2011 Americ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Arthur_(2011_film)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Murder on the Orient Express (1974 film)</td>\n",
       "      <td>Murder on the Orient Express         ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Murder_on_the_Or...</td>\n",
       "      <td>0.98560670156585</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Title  \\\n",
       "0                                 Inception   \n",
       "1                        Arthur (2011 film)   \n",
       "2                                 Inception   \n",
       "3                        Arthur (2011 film)   \n",
       "4  Murder on the Orient Express (1974 film)   \n",
       "\n",
       "                                               Intro  \\\n",
       "0           Inception               is a 2010    ...   \n",
       "1           Arthur               is a 2011 Americ...   \n",
       "2           Inception               is a 2010    ...   \n",
       "3           Arthur               is a 2011 Americ...   \n",
       "4           Murder on the Orient Express         ...   \n",
       "\n",
       "                                                 Url        Similarity  \n",
       "0            https://en.wikipedia.org/wiki/Inception                 1  \n",
       "1   https://en.wikipedia.org/wiki/Arthur_(2011_film)                 1  \n",
       "2            https://en.wikipedia.org/wiki/Inception                 1  \n",
       "3   https://en.wikipedia.org/wiki/Arthur_(2011_film)                 1  \n",
       "4  https://en.wikipedia.org/wiki/Murder_on_the_Or...  0.98560670156585  "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = list(input().split())\n",
    "searchengine2(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "know light film star\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Intro</th>\n",
       "      <th>Url</th>\n",
       "      <th>Similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adventures of Captain Marvel</td>\n",
       "      <td>Adventures of Captain Marvel         ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Adventures_of_Ca...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Hour Before the Dawn</td>\n",
       "      <td>The Hour Before the Dawn             ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Hour_Before_...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Journey into Light</td>\n",
       "      <td>Journey into Light               is a...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Journey_into_Light</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adventures of Captain Marvel</td>\n",
       "      <td>Adventures of Captain Marvel         ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Adventures_of_Ca...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Hour Before the Dawn</td>\n",
       "      <td>The Hour Before the Dawn             ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Hour_Before_...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Journey into Light</td>\n",
       "      <td>Journey into Light               is a...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Journey_into_Light</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Adventures of Captain Marvel</td>\n",
       "      <td>Adventures of Captain Marvel         ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Adventures_of_Ca...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The Hour Before the Dawn</td>\n",
       "      <td>The Hour Before the Dawn             ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Hour_Before_...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Journey into Light</td>\n",
       "      <td>Journey into Light               is a...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Journey_into_Light</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Surviving the Game</td>\n",
       "      <td>Surviving the Game               is a...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Surviving_the_Game</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Fools Rush In (1997 film)</td>\n",
       "      <td>Fools Rush In               is a 1997...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Fools_Rush_In_(1...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Night of the Demons 3</td>\n",
       "      <td>Night of the Demons 3               (...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Night_of_the_Dem...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Stir of Echoes</td>\n",
       "      <td>Stir of Echoes               is a 199...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Stir_of_Echoes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Corky Romano</td>\n",
       "      <td>Corky Romano               is a 2001 ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Corky_Romano</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Stolen (2012 film)</td>\n",
       "      <td>Stolen               , formerly known...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Stolen_(2012_film)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>From Hell to Texas</td>\n",
       "      <td>From Hell to Texas               is a...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/From_Hell_to_Texas</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Silent Running</td>\n",
       "      <td>Silent Running               is a 197...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Silent_Running</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>A Dark Song</td>\n",
       "      <td>A Dark Song               is a 2016 I...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/A_Dark_Song</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Surviving the Game</td>\n",
       "      <td>Surviving the Game               is a...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Surviving_the_Game</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Fools Rush In (1997 film)</td>\n",
       "      <td>Fools Rush In               is a 1997...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Fools_Rush_In_(1...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Night of the Demons 3</td>\n",
       "      <td>Night of the Demons 3               (...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Night_of_the_Dem...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Title  \\\n",
       "0   Adventures of Captain Marvel   \n",
       "1       The Hour Before the Dawn   \n",
       "2             Journey into Light   \n",
       "3   Adventures of Captain Marvel   \n",
       "4       The Hour Before the Dawn   \n",
       "5             Journey into Light   \n",
       "6   Adventures of Captain Marvel   \n",
       "7       The Hour Before the Dawn   \n",
       "8             Journey into Light   \n",
       "9             Surviving the Game   \n",
       "10     Fools Rush In (1997 film)   \n",
       "11         Night of the Demons 3   \n",
       "12                Stir of Echoes   \n",
       "13                  Corky Romano   \n",
       "14            Stolen (2012 film)   \n",
       "15            From Hell to Texas   \n",
       "16                Silent Running   \n",
       "17                   A Dark Song   \n",
       "18            Surviving the Game   \n",
       "19     Fools Rush In (1997 film)   \n",
       "20         Night of the Demons 3   \n",
       "\n",
       "                                                Intro  \\\n",
       "0            Adventures of Captain Marvel         ...   \n",
       "1            The Hour Before the Dawn             ...   \n",
       "2            Journey into Light               is a...   \n",
       "3            Adventures of Captain Marvel         ...   \n",
       "4            The Hour Before the Dawn             ...   \n",
       "5            Journey into Light               is a...   \n",
       "6            Adventures of Captain Marvel         ...   \n",
       "7            The Hour Before the Dawn             ...   \n",
       "8            Journey into Light               is a...   \n",
       "9            Surviving the Game               is a...   \n",
       "10           Fools Rush In               is a 1997...   \n",
       "11           Night of the Demons 3               (...   \n",
       "12           Stir of Echoes               is a 199...   \n",
       "13           Corky Romano               is a 2001 ...   \n",
       "14           Stolen               , formerly known...   \n",
       "15           From Hell to Texas               is a...   \n",
       "16           Silent Running               is a 197...   \n",
       "17           A Dark Song               is a 2016 I...   \n",
       "18           Surviving the Game               is a...   \n",
       "19           Fools Rush In               is a 1997...   \n",
       "20           Night of the Demons 3               (...   \n",
       "\n",
       "                                                  Url Similarity  \n",
       "0   https://en.wikipedia.org/wiki/Adventures_of_Ca...          1  \n",
       "1   https://en.wikipedia.org/wiki/The_Hour_Before_...          1  \n",
       "2    https://en.wikipedia.org/wiki/Journey_into_Light          1  \n",
       "3   https://en.wikipedia.org/wiki/Adventures_of_Ca...          1  \n",
       "4   https://en.wikipedia.org/wiki/The_Hour_Before_...          1  \n",
       "5    https://en.wikipedia.org/wiki/Journey_into_Light          1  \n",
       "6   https://en.wikipedia.org/wiki/Adventures_of_Ca...          1  \n",
       "7   https://en.wikipedia.org/wiki/The_Hour_Before_...          1  \n",
       "8    https://en.wikipedia.org/wiki/Journey_into_Light          1  \n",
       "9    https://en.wikipedia.org/wiki/Surviving_the_Game          1  \n",
       "10  https://en.wikipedia.org/wiki/Fools_Rush_In_(1...          1  \n",
       "11  https://en.wikipedia.org/wiki/Night_of_the_Dem...          1  \n",
       "12       https://en.wikipedia.org/wiki/Stir_of_Echoes          1  \n",
       "13         https://en.wikipedia.org/wiki/Corky_Romano          1  \n",
       "14   https://en.wikipedia.org/wiki/Stolen_(2012_film)          1  \n",
       "15   https://en.wikipedia.org/wiki/From_Hell_to_Texas          1  \n",
       "16       https://en.wikipedia.org/wiki/Silent_Running          1  \n",
       "17          https://en.wikipedia.org/wiki/A_Dark_Song          1  \n",
       "18   https://en.wikipedia.org/wiki/Surviving_the_Game          1  \n",
       "19  https://en.wikipedia.org/wiki/Fools_Rush_In_(1...          1  \n",
       "20  https://en.wikipedia.org/wiki/Night_of_the_Dem...          1  "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = list(input().split())\n",
    "searchengine2(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disney movie 2019\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Intro</th>\n",
       "      <th>Url</th>\n",
       "      <th>Similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thumbelina (1994 film)</td>\n",
       "      <td>Thumbelina               (also known ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Thumbelina_(1994...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Avengers (2012 film)</td>\n",
       "      <td>Marvel's The Avengers                ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Avengers_(20...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cars 3</td>\n",
       "      <td>Cars 3               is a 2017 Americ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Cars_3</td>\n",
       "      <td>0.94335701356643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Frozen (2013 film)</td>\n",
       "      <td>Frozen               is a 2013 Americ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Frozen_(2013_film)</td>\n",
       "      <td>0.89654294215813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Chronicles of Narnia: Prince Caspian</td>\n",
       "      <td>The Chronicles of Narnia: Prince Casp...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Chronicles_o...</td>\n",
       "      <td>0.82684193281763</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Title  \\\n",
       "0                    Thumbelina (1994 film)   \n",
       "1                  The Avengers (2012 film)   \n",
       "2                                    Cars 3   \n",
       "3                        Frozen (2013 film)   \n",
       "4  The Chronicles of Narnia: Prince Caspian   \n",
       "\n",
       "                                               Intro  \\\n",
       "0           Thumbelina               (also known ...   \n",
       "1           Marvel's The Avengers                ...   \n",
       "2           Cars 3               is a 2017 Americ...   \n",
       "3           Frozen               is a 2013 Americ...   \n",
       "4           The Chronicles of Narnia: Prince Casp...   \n",
       "\n",
       "                                                 Url        Similarity  \n",
       "0  https://en.wikipedia.org/wiki/Thumbelina_(1994...                 1  \n",
       "1  https://en.wikipedia.org/wiki/The_Avengers_(20...                 1  \n",
       "2               https://en.wikipedia.org/wiki/Cars_3  0.94335701356643  \n",
       "3   https://en.wikipedia.org/wiki/Frozen_(2013_film)  0.89654294215813  \n",
       "4  https://en.wikipedia.org/wiki/The_Chronicles_o...  0.82684193281763  "
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = list(input().split())\n",
    "searchengine2(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "light light light film sun\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Intro</th>\n",
       "      <th>Url</th>\n",
       "      <th>Similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Multi-Facial</td>\n",
       "      <td>Multi-Facial               is a 1995 ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Multi-Facial</td>\n",
       "      <td>0.9999935714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Legend (1985 film)</td>\n",
       "      <td>Legend               is a 1985 Americ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Legend_(1985_film)</td>\n",
       "      <td>0.999985536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Blade II</td>\n",
       "      <td>Blade II               is a 2002 Amer...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Blade_II</td>\n",
       "      <td>0.9999598243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Close Encounters of the Third Kind</td>\n",
       "      <td>Close Encounters of the Third Kind   ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Close_Encounters...</td>\n",
       "      <td>0.9998698517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Little Monsters</td>\n",
       "      <td>Little Monsters               is a 19...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Little_Monsters</td>\n",
       "      <td>0.9980234564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Midnight Special (film)</td>\n",
       "      <td>Midnight Special               is a 2...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Midnight_Special...</td>\n",
       "      <td>0.9980109468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Pitch Black (film)</td>\n",
       "      <td>Pitch Black               (titled    ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Pitch_Black_(film)</td>\n",
       "      <td>0.9980109468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The Hallow</td>\n",
       "      <td>The Hallow               (originally ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Hallow</td>\n",
       "      <td>0.9948607933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>League of Gods</td>\n",
       "      <td>League of Gods               (       ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/League_of_Gods</td>\n",
       "      <td>0.9928853908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The Wraith</td>\n",
       "      <td>The Wraith               is a 1986   ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Wraith</td>\n",
       "      <td>0.9928681177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Home (2015 film)</td>\n",
       "      <td>Home               is a 2015 American...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Home_(2015_anima...</td>\n",
       "      <td>0.9927539708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Curious George (film)</td>\n",
       "      <td>Curious George               is a 200...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Curious_George_(...</td>\n",
       "      <td>0.9927539708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Pretty Woman</td>\n",
       "      <td>Pretty Woman               is a 1990 ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Pretty_Woman</td>\n",
       "      <td>0.9927088611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Hocus Pocus (1993 film)</td>\n",
       "      <td>Hocus Pocus               is a 1993 A...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Hocus_Pocus_(199...</td>\n",
       "      <td>0.9925987732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Megiddo: The Omega Code 2</td>\n",
       "      <td>Megiddo: The Omega Code 2            ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Megiddo:_The_Ome...</td>\n",
       "      <td>0.9918982343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>The Tree of Life (film)</td>\n",
       "      <td>The Tree of Life               is a 2...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Tree_of_Life...</td>\n",
       "      <td>0.9739265829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>A Far Off Place</td>\n",
       "      <td>A Far Off Place               (aka   ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/A_Far_Off_Place</td>\n",
       "      <td>0.9159937312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>I Love You, Beth Cooper (film)</td>\n",
       "      <td>I Love You, Beth Cooper              ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/I_Love_You,_Beth...</td>\n",
       "      <td>0.9159937312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Atlantis, the Lost Continent</td>\n",
       "      <td>Atlantis, the Lost Continent         ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Atlantis,_the_Lo...</td>\n",
       "      <td>0.9159937312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>I Love You, Beth Cooper (film)</td>\n",
       "      <td>I Love You, Beth Cooper              ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/I_Love_You,_Beth...</td>\n",
       "      <td>0.9159937312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Atlantis, the Lost Continent</td>\n",
       "      <td>Atlantis, the Lost Continent         ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Atlantis,_the_Lo...</td>\n",
       "      <td>0.9159937312</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Title  \\\n",
       "0                         Multi-Facial   \n",
       "1                   Legend (1985 film)   \n",
       "2                             Blade II   \n",
       "3   Close Encounters of the Third Kind   \n",
       "4                      Little Monsters   \n",
       "5              Midnight Special (film)   \n",
       "6                   Pitch Black (film)   \n",
       "7                           The Hallow   \n",
       "8                       League of Gods   \n",
       "9                           The Wraith   \n",
       "10                    Home (2015 film)   \n",
       "11               Curious George (film)   \n",
       "12                        Pretty Woman   \n",
       "13             Hocus Pocus (1993 film)   \n",
       "14           Megiddo: The Omega Code 2   \n",
       "15             The Tree of Life (film)   \n",
       "16                     A Far Off Place   \n",
       "17      I Love You, Beth Cooper (film)   \n",
       "18        Atlantis, the Lost Continent   \n",
       "19      I Love You, Beth Cooper (film)   \n",
       "20        Atlantis, the Lost Continent   \n",
       "\n",
       "                                                Intro  \\\n",
       "0            Multi-Facial               is a 1995 ...   \n",
       "1            Legend               is a 1985 Americ...   \n",
       "2            Blade II               is a 2002 Amer...   \n",
       "3            Close Encounters of the Third Kind   ...   \n",
       "4            Little Monsters               is a 19...   \n",
       "5            Midnight Special               is a 2...   \n",
       "6            Pitch Black               (titled    ...   \n",
       "7            The Hallow               (originally ...   \n",
       "8            League of Gods               (       ...   \n",
       "9            The Wraith               is a 1986   ...   \n",
       "10           Home               is a 2015 American...   \n",
       "11           Curious George               is a 200...   \n",
       "12           Pretty Woman               is a 1990 ...   \n",
       "13           Hocus Pocus               is a 1993 A...   \n",
       "14           Megiddo: The Omega Code 2            ...   \n",
       "15           The Tree of Life               is a 2...   \n",
       "16           A Far Off Place               (aka   ...   \n",
       "17           I Love You, Beth Cooper              ...   \n",
       "18           Atlantis, the Lost Continent         ...   \n",
       "19           I Love You, Beth Cooper              ...   \n",
       "20           Atlantis, the Lost Continent         ...   \n",
       "\n",
       "                                                  Url    Similarity  \n",
       "0          https://en.wikipedia.org/wiki/Multi-Facial  0.9999935714  \n",
       "1    https://en.wikipedia.org/wiki/Legend_(1985_film)   0.999985536  \n",
       "2              https://en.wikipedia.org/wiki/Blade_II  0.9999598243  \n",
       "3   https://en.wikipedia.org/wiki/Close_Encounters...  0.9998698517  \n",
       "4       https://en.wikipedia.org/wiki/Little_Monsters  0.9980234564  \n",
       "5   https://en.wikipedia.org/wiki/Midnight_Special...  0.9980109468  \n",
       "6    https://en.wikipedia.org/wiki/Pitch_Black_(film)  0.9980109468  \n",
       "7            https://en.wikipedia.org/wiki/The_Hallow  0.9948607933  \n",
       "8        https://en.wikipedia.org/wiki/League_of_Gods  0.9928853908  \n",
       "9            https://en.wikipedia.org/wiki/The_Wraith  0.9928681177  \n",
       "10  https://en.wikipedia.org/wiki/Home_(2015_anima...  0.9927539708  \n",
       "11  https://en.wikipedia.org/wiki/Curious_George_(...  0.9927539708  \n",
       "12         https://en.wikipedia.org/wiki/Pretty_Woman  0.9927088611  \n",
       "13  https://en.wikipedia.org/wiki/Hocus_Pocus_(199...  0.9925987732  \n",
       "14  https://en.wikipedia.org/wiki/Megiddo:_The_Ome...  0.9918982343  \n",
       "15  https://en.wikipedia.org/wiki/The_Tree_of_Life...  0.9739265829  \n",
       "16      https://en.wikipedia.org/wiki/A_Far_Off_Place  0.9159937312  \n",
       "17  https://en.wikipedia.org/wiki/I_Love_You,_Beth...  0.9159937312  \n",
       "18  https://en.wikipedia.org/wiki/Atlantis,_the_Lo...  0.9159937312  \n",
       "19  https://en.wikipedia.org/wiki/I_Love_You,_Beth...  0.9159937312  \n",
       "20  https://en.wikipedia.org/wiki/Atlantis,_the_Lo...  0.9159937312  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = list(input().split())\n",
    "searchengine2(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ex[3] build a new engine with a personal Score!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
