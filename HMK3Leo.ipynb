{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [1.1] Get the list of movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(open('C:/Users/leona/Desktop/ADMHMK-3/movies1.html'), \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<style>\n",
       " table, th, td {border: 1px solid black;}</style>,\n",
       " <link href=\"https://www.w3schools.com/browserref.css\" rel=\"stylesheet\" type=\"text/css\"/>]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_a = soup.select('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lst_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = []\n",
    "for i in lst_a:\n",
    "    urls.append(i.get('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now I have a list with all the urls, so let's start the next point!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [1.2] Crawl Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.error import URLError, HTTPError, ContentTooShortError\n",
    "import time\n",
    "k=0\n",
    "for i in range(len(urls)):\n",
    "    try:\n",
    "        ur_l = requests.get(urls[i])\n",
    "        soup = BeautifulSoup(ur_l.content, 'html.parser')\n",
    "        soup = soup.prettify(\"utf-8\")        \n",
    "        stringa = 'Articles/article-'+str(k)+'.html'\n",
    "        k = k+1\n",
    "        Html_file= open(stringa, \"wb\")\n",
    "        Html_file.write(soup)\n",
    "        Html_file.close()\n",
    "    except(URLError,HTTPError, ContentTooShortError)  as e:\n",
    "        html = None\n",
    "    time.sleep(1)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [1.3] Parse downloaded pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "myfile = open(\"Articles/article-0.html\")\n",
    "#soup = BeautifulSoup(myfile, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import io\n",
    "for i in range(10000):\n",
    "    filename = \"Articles/article-\"+str(i)+\".html\"\n",
    "    with open(filename, encoding=\"utf-8\") as f:\n",
    "        data = f.read()\n",
    "        soup = BeautifulSoup(data, 'html.parser')\n",
    "        #Now That I opened the file I have to look for the section asked\n",
    "        titlepage = soup.title.string\n",
    "        titleonly = titlepage.split(\"- Wikipedia\")\n",
    "        titlepage = titleonly[0].strip()\n",
    "        intro = ''\n",
    "        plot = ''\n",
    "        start = soup.find('p')\n",
    "        intro = start\n",
    "        intro1 = start.text\n",
    "        #print('EILa')\n",
    "        B = ''\n",
    "        B = intro.find_next_sibling('h2')\n",
    "        if(B!=None and B.find_next_sibling('p')):\n",
    "            C = B.find_next_sibling('p')\n",
    "            #print(intro1)\n",
    "            #print(intro.find_next_sibling('p'))\n",
    "            #print(B)\n",
    "            while(C != intro.find_next_sibling('p')): \n",
    "                intro1 = intro1 + intro.find_next_sibling('p').text\n",
    "                intro = intro.find_next_sibling('p')\n",
    "            plot = ''            \n",
    "            plot = B\n",
    "        #print(intro)\n",
    "            plot1 = ''\n",
    "            compare = ''\n",
    "            if(B.find_next_sibling('h2')):\n",
    "                compare = B.find_next_sibling('h2')\n",
    "                compareto = compare.find_next_sibling('p')\n",
    "                #plot1 = B.find_next_sibling('p').text\n",
    "                #print(compareto)\n",
    "                #print(plot1)\n",
    "                while(compareto != plot.find_next_sibling('p')):\n",
    "                    plot1 = plot1 + plot.find_next_sibling('p').text\n",
    "                    #print(plot1)\n",
    "                    plot = plot.find_next_sibling('p')\n",
    "        if(intro1 == ''):\n",
    "            intro1 = \"NA\"\n",
    "        if plot1 == '':\n",
    "            plot1 = \"NA\"\n",
    "        intro = intro1\n",
    "        plot = plot1\n",
    "        film_name = 'NA'\n",
    "        director = \"NA\"\n",
    "        producer = \"NA\"\n",
    "        writer = \"NA\"\n",
    "        starring = \"NA\"\n",
    "        music = \"NA\"\n",
    "        release_date = \"NA\"\n",
    "        runtime = \"NA\"\n",
    "        country = \"NA\"\n",
    "        language = \"NA\"\n",
    "        budget = \"NA\"\n",
    "#'film_name', 'director', 'producer','writer', 'starring', 'music', 'release date', 'runtime', 'country', 'language', 'budget'\n",
    "        for link in soup.find_all('tr'):\n",
    "            if soup.find('th',{'class': ['summary']})!= None:\n",
    "                    film_name = soup.find('th',{'class': ['summary']} ).text.strip()\n",
    "            if link.th:\n",
    "                if(link.th.text.strip() == 'Directed by'):\n",
    "                     director = link.td.text.strip()\n",
    "                elif(link.th.text.strip() == 'Produced by'):\n",
    "                      producer = link.td.text.strip()\n",
    "                elif(link.th.text.strip() == 'Written by'):\n",
    "                    writer = link.td.text.strip()\n",
    "                elif(link.th.text.strip() == 'Starring'):\n",
    "                    starring = link.td.text.strip()\n",
    "                elif(link.th.text.strip() == 'Music by'):\n",
    "                     music = link.td.text.strip()               \n",
    "                elif(link.th.text.strip() == 'Release date'):\n",
    "                    release_date = link.td.text.strip()\n",
    "                elif(link.th.text.strip() == 'Running time'):\n",
    "                    runtime = link.td.text.strip()\n",
    "                elif(link.th.text.strip() == 'Country'):\n",
    "                    if link.td:\n",
    "                        country = link.td.text.strip()\n",
    "                elif(link.th.text.strip() == 'Language'):\n",
    "                    language = link.td.text.strip()\n",
    "                elif(link.th.text.strip() == 'Budget'):\n",
    "                    budget = link.td.text.strip()\n",
    "        \n",
    "        tsvname = 'Tsvfiles/'+'film'+str(i)\n",
    "        with io.open(tsvname, \"w\", encoding=\"utf-8\") as out_file:\n",
    "        #with open(tsvname, 'w') as out_file:\n",
    "            tsv_writer = csv.writer(out_file, delimiter='\\t')\n",
    "            tsv_writer.writerow(['title','intro', 'plot', 'film_name', 'director', 'producer','writer', 'starring', 'music', 'release date', 'runtime', 'country', 'language', 'budget'])\n",
    "            tsv_writer.writerow([titlepage, intro, plot, film_name, director, producer, writer, starring, music, release_date, runtime, \n",
    "                 country, language, budget])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "         Should a Woman Divorce?\n",
      "        \n",
      "\n",
      "       is a\n",
      "       \n",
      "        1914\n",
      "       \n",
      "\n",
      "        silent film\n",
      "       \n",
      "       written by\n",
      "       \n",
      "        Ivan Abramson\n",
      "       \n",
      "       and directed by\n",
      "       \n",
      "        Edwin McKim\n",
      "       \n",
      "       , and starring Lea Leland and Leonid Samoloff.\n",
      "      \n",
      "POI PLOT\n",
      "\n",
      "       Grace Roberts (played by Lea Leland), marries rancher Edward Smith, who is revealed to be a neglectful, vice-ridden spouse.  They have a daughter, Vivian.  Dr. Franklin (Leonid Samoloff) whisks Grace away from this unhappy life, and they move to New York under aliases, pretending to be married (since surely Smith would not agree to a divorce).  Grace and Franklin have a son, Walter (\n",
      "       \n",
      "        Milton S. Gould\n",
      "       \n",
      "       ).  Vivian gets sick, however, and Grace and Franklin return to save her.   Somehow this reunion, as Smith had assumed Grace to be dead, causes the death of Franklin.   This plot device frees Grace to return to her father's farm with both children.\n",
      "       \n",
      "\n",
      "         [1]\n",
      "        \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "intro = ''\n",
    "plot = ''\n",
    "start = soup.find('p')\n",
    "intro = start\n",
    "intro1 = start.text\n",
    "#print('EILa')\n",
    "B = ''\n",
    "B = intro.find_next_sibling('h2')\n",
    "C = B.find_next_sibling('p')\n",
    "#print(intro1)\n",
    "#print(intro.find_next_sibling('p'))\n",
    "#print(B)\n",
    "while(C != intro.find_next_sibling('p')): \n",
    "            intro1= intro1 + intro.find_next_sibling('p').text\n",
    "            intro = intro.find_next_sibling('p')\n",
    "plot = ''            \n",
    "plot = B\n",
    "#print(intro)\n",
    "plot1 = ''\n",
    "compare = ''\n",
    "compare = B.find_next_sibling('h2')\n",
    "compareto = compare.find_next_sibling('p')\n",
    "#plot1 = B.find_next_sibling('p').text\n",
    "#print(compareto)\n",
    "#print(plot1)\n",
    "while(compareto != plot.find_next_sibling('p')):\n",
    "        plot1 = plot1 + plot.find_next_sibling('p').text\n",
    "        #print(plot1)\n",
    "        plot = plot.find_next_sibling('p')\n",
    "        #print(plot)\n",
    "print(intro1)\n",
    "print(\"POI PLOT\")\n",
    "print(plot1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\leona\\anaconda3\\lib\\site-packages (3.4.5)\n",
      "Requirement already satisfied: six in c:\\users\\leona\\anaconda3\\lib\\site-packages (from nltk) (1.12.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    \\r\\n       The film is memorable for its use o...\n",
       "Name: plot, dtype: object"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dataset1 = pd.read_csv('Tsvfiles/film4', delimiter='\\t')\n",
    "dataset1['plot']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
